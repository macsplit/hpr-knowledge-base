Episode: 2517
Title: HPR2517: DIY CCTV Security System
Source: https://hub.hackerpublicradio.org/ccdn.php?filename=/eps/hpr2517/hpr2517.mp3
Transcribed: 2025-10-19 04:35:16

---

This in HPR episode 2,517 entitled DIY CCTV Security System,
it is hosted by Opera Nero R and in about 16 minutes long and Karima Clean Flag.
The summary is, I go over my own CCTV setup.
This episode of HPR is brought to you by archive.org.
Support universal access to all knowledge by heading over to archive.org forward slash donate.
Hello and welcome to another episode of Active Rubble Gradyo with your host operator.
Today I'm going to be talking to you about the security system I have and setup.
This uses Zollminder and open source application along with a couple of security cameras
and some object recognition software.
The actual system that performs the work is a media center box.
So you may need to have a semi beefy CPU for this or a ridiculously expensive GPU and I'll
I might go into some of that. First things first, the idea is that I didn't want to purchase a
blinky box, right? Everybody has had some experience with you know seeing those in stores and
things like that. I knew and did some looking around. There were some offerings in the cloud
that did some of what I wanted to do but it was never 100% and not super interested in having
all that information sent to the cloud who already knows everything about and more about myself
and my wife at least. So I wanted to build my own because I knew the limitations of that thing
would not be what I wanted. So what I had ended up with is a real link RLC 410S. This has a
on premise or an internal 16 gig thing that I think can be expanded. You might have to take it
apart or something but it's got 16 gigs on it. You can buy a non-16 gig for 65, the 16 gig
one is 80 bucks. This is you know considered HD 252, 560 by 1440. So it sounds like crazy if
you're talking about it but it's you know pretty standard. Just considered a bullet camera,
they do have domes, things like that for indoor. So what we have is a front camera facing the door,
the house, the front door and a rear facing the rear door and some of the other windows and things
like that. There's a lot of stuff around online that will tell you where to put them, where not to
put them. You want to put them in the plane site, you want to put them about I want to say 8 feet,
9 feet above. So without a reach but actually you want to keep them in sight and close enough to
your target. So at night when the infrared turns on you know it's not too far away.
So first thing I had to do was set up a voice over IP or not voice over IP but a power of
a Ethernet setup. I got a Lynxis 150, this one's a LG S116P 16 port. I think the first 8 are
power and the rest are standard. It's supposed to be gigabit and the idea there is get all your
wires set up, test it, make sure it actually works and start wiring things. I have a fishing
a fishing tape that I use for that and there's also what helps is a toning a toner tone generator
so you can kind of hunt the cables as they get lost inside the back of the wall. I did have some
issues actually running these but in general it's pretty standard and you'll get better as you run
more and more. I would advise against wireless obviously because these are high bandwidth environments
with these giant resolution cameras and heavy frame rates. As high as 15 frames per second
even if 25, 30 any stuff something around that range when they're first out of the box. So we
we end up clocking it down which I'll go into later. The thing you want to start with is really
called for Windows if you have Windows and want to have a quick look at this. I would start with
iSpy. It has some object recognition built into it and it's pretty decent. It's all CPU based, not
GPU based, all that. What I used is Zone Minder and Zone Minder again is open source. So the cameras
are plugged into the power ethernet switch that goes to the media box and we have two sources
for the media box and that goes to Zone Minder. Now when Zone Minder creates an event I've got
Zone set up so we have Zones for each distance essentially. One is for near, one is for far. The far
is obviously a higher sensitivity and the closer one is normal sensitivity and then we have
a perclusion zone for the street which is actually cars passing by. They say the best thing you can
do is actually capture a license plate and I might go over that if I end up building a manual
profile for a stationary license plate reader for the nighttime and daytime. So the idea there is
that it kind of futs around with it at first, get the set up right, get the positioning right,
kind of get a feel for what it looks like and start getting into Zone Minder and the Zones and
raising the sensitivity and after you've got all that set up then you can start getting into
the yellow stuff which is the dark net in object recognition. My experience by this board is probably
three, four or five years old and it takes about 10 seconds per image. Now if you have like a
four gig card you can use yellow with GPU processing and do some real-time craziness.
If you have, I want to use tiny yellow which haven't had the best luck with you can actually get
away with like a two gig card they say. So the way it works is when an event in Zone Minder is closed
it actually picks a random 10 images out of the event. Now that's an issue if there is motion
that's actual legitimate motion and in those frames maybe that's a lot of motion. So for example
if someone's having a fight in the front yard and it picks a random 10 images that motion might not
be part of something else and you might not catch your target. But generally speaking if there's
motion within 10 frames of all of that or any of that motion there's probably going to be an object
at some point in time. So I opted out of capturing all the frames instead of just capturing the 10 random
frames to be processed by the object recognition. So I filter out everything that's not a person,
dog cat or a car. There's a lot of objects within yellow by default and the future state would be
to only configure it to load those profiles and it would make the processing much faster right.
If you're only looking for person dog cat car then it's only going to have to look for that and
insignificantly lower the speed. And that's about creating your own filters essentially or
what they call them. I can't remember the name off the top of my head. So if an object is detected
we look to the C if two Android phones are on the network meaning that if my wife's phone or
my phone is on the network right it won't notify us but every hour. So the idea there is if we're
both home and we're playing out in front of the yard with the kids if we're not going to get blown
up with alerts and emails and flooded with every time you throw a ball right. So that helps with that
part of it. With a reason we have it throttles or even on at all when we're home is for example if
we receive a package or maybe an in law comes over or a relative comes over and we generally will
usually pick that up unless you know you go out on the side and then within 30 minutes you come back
in and something another event happens. So they're throttled to about one hour per hour we get in
the event. If nobody's home the original event is actually sent that yellow detected. So
there's there's also that presented so I think I have it set for like 60 75 percent if not 60
percent for each one of the definitions and I've got a video in the show notes for for what that
kind of looks like. Other than that there's a lot of really ugly bash code that's that I've got
in the show notes that actually show how functionally this works. What I'll do is tell you about
issues so what a lot of people don't think is rain things like spider webs across the
the infrared and if a spider web gets cast across the the camera that's fine but what happens is
when the infrared turns on it lights up like a Christmas tree and the slightest bit of wind
causes motion because it's so close to the camera. So what I'll do is I'll have a little bit of
bug spray and actually use kind of some outdoor bug spray and I use that to kind of keep that area
free of different insects and webby casty types of critters. Let's see car lights again
talk about preclusion so that's probably a big help. It's sorting all that out. Full motion
capture I can do on the card about 16 or six hours per the 16 gigs I want to say. In general that's
kind of what it covers or more or less because if it rains or if you don't actually go outside or
depending so I really want to say it's anywhere from six hours to the heavy end would be maybe 12
and maybe a full day and on the low end if it's raining all day and you get flooded with events
you might even get a little as two hours if it's capturing two hours straight but in general it
seems like it's about six hours and I've missed out on some things like different things in the
yard that I've wanted to capture the full motion for so I think it's around 60 gigs with the full
frame rate and all that and I might do some tweaking with that. Another thing you'll experience is
smearing and there or you may not experience and the idea there is that you set the max frame rate
lower to what's in Zillminder and that can help. There's also you can switch between FF
Impag and I'm using Remote and those are similar but from what I understand different as the way
they work. I was more successful with the remote but I had quite a few errors, constant errors inside
of Zillminder about seeking issues and things like that mainly because I'm trying to capture too many
frames for second basically I think. In System D I'm kind of not getting the messages that are
coming out of my batch script for whatever reason. Another thing I'll mention is at nighttime
the frame rate is obviously slower so it can have a longer exposure time so you can actually get
a better image but if the image is moving more if the object is moving it's pretty hard for
yellow to detect what that object is so at night you might get a person to detect it as a dog
or you might get a stationary object detected as a dog if it's sitting there at night.
Mainly the blurring is what really breaks the whole object recognition stuff.
I would start with other tips I would say start with low settings for the sensitivity and
again start raising it in each zone until it starts tripping and you want to do this over time
right so you want a little raises sensitivity let it rain check it out see how it goes let it go
through net goal overnight through a overnight setting so honestly the best time to experiment with
this stuff is kind of before it rains or even when it's raining that that helps or also during
a really bright day where there's lots of shadows being cast excuse me on that stuff
and my light just went out another thing I'll say is I think that's pretty much set
I'll do overload ignore frame counts so for example if there's only two frames of motion then I'll
kick that out meaning that if someone is walking towards your house or the target that I'm looking
for are probably going to contain more than 5 frames 10 frames right so I think I have the throttle
set to 10 frames and I also have it drop off the beginning and in of the event so traditionally I
think it captures the first and last 20 frames I might turn that back on now that I'm only
capturing 10 random frames but that's going to set in the pool of the 10 random frames for the
object recognition and one of those frames 10 of those frames could potentially be the 40 they're
originally captured before and after but it's really a reference but the overload ignore frame
count is pretty pretty significant and also there's the alarm frame count that you want to kind of
take a look at too there's for the preclusion zones you also want to raise that so if it's a default
of 10 then it's probably going to be more than 10 frames for the for the preclusion zone so for
example a car drives by that's a lot more than 10 frames so it might be up to 20 frames or
even more for for that type of lighting event to cause motion other than that we're we're
pretty happy with what we got we pick up all those other people we'll pick up people driving
the driveway and then laws and stuff but I guess the next part of the project will be to
somehow capture the street we live on a single street so I would like to somehow capture both
directions which that would require having two more cameras which would significantly double
the amount of bandwidth potentially but not necessarily if it's capturing a stationary object
and only trying to do light display and read license plates so that's that's the the predicament
there is that the license plate information is is pretty important but to capture it you'd want
to have a camera going both directions or at least if you have it in one direction you would have
the note that the target is going to be within that range and either drive to it or drive past it
to be able to connect or to be able to pull a license plate off of that so there's some logic
issues I'm working through for the license plate stuff then I may or may not pull the trigger on
because honestly we haven't had any issues knocked on wood within our neighborhood here so
anyways I haven't recorded an episode in a while and I've got a few down the pipe and if you
have any ideas or questions let me know and feel free to contribute I'm hopefully going to start
having some more interview type of setups and get some kind of co-hosts on the deal and get
some conversations going that are a little bit less boring than me just battling on about stuff
for hours at a time right
you've been listening to hecka public radio at hecka public radio dot org
we are a community podcast network that releases shows every weekday Monday through Friday
today's show like all our shows was contributed by an HBR listener like yourself
if you ever thought of recording a podcast and click on our contributing to find out how easy it
really is hecka public radio was founded by the digital dot pound and the infonomicant computer club
and it's part of the binary revolution at binrev.com if you have comments on today's show
please email the host directly leave a comment on the website or record a follow-up episode yourself
on this otherwise status today's show is released on the creative comments
attribution share light 3.0 license
