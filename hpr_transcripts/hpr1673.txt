Episode: 1673
Title: HPR1673: How I use ZFS on Linux
Source: https://hub.hackerpublicradio.org/ccdn.php?filename=/eps/hpr1673/hpr1673.mp3
Transcribed: 2025-10-18 06:45:44

---

This is HPR episode 1673 entitled How I Use CFS on Linux and is part of the series file systems.
It is hosted by first-time host Mitchell Sierishinsky-Aka, Mindbender and is about 17 minutes long.
The summary is the CFS file system and how I use it under Linux.
This episode of HPR is brought to you by an honesthost.com.
Get 15% discount on all shared hosting with the offer code HPR15.
That's HPR15.
Better web hosting that's honest and fair at an honesthost.com.
Hey everybody, this is Michael, aka Mindbender.
Recording my first podcast for Hacker Public Radio.
I wanted to speak to you guys a little bit about some of the things that I'm into.
I've been using Linux often on for the last 10 years or so.
I started out with Fedora Core 2 way back in the day and honestly at the time I had very little
knowledge base about Linux in general.
However, since that time I've used it on a number of devices actually put together a few servers
that I've used for storing files around my house.
What I want to speak to you guys today about is something that I know has already been
discussed on the Hacker Public Radio is the CFS file system.
It is a very powerful and as they say the last word in file systems,
very powerful tool that we have in the open source community.
Now, CFS has been around for a number of years at this point and is very stable file system.
But it originates mostly from Sun Microsystems now Oracle originally used in the Solaris
Operating System was ported over to the BSDs and honestly I feel that it is the BSDs killer feature.
Licensing makes it a bit of an issue. It's released under a open source but license but it's not
compatible with the GPL that Linux is. So unfortunately it has never been compiled into Linux itself.
But it can be used in various ways with Linux. Two ways I'd know of is the fuse file system
which I'm honestly not that knowledgeable about because I've never used this method.
I've been told it might be slower if anybody else wants to come in on that please do.
But also there is also a project known as the ZFS on Linux project.
Now more information about this project can be found at ZFS on Linux.org.
As I say on their main website it's a native Linux kernel port of the ZFS file system so it
actually works at the kernel level. And they have pre-compiled binaries as well as
various as well as repositories for a number of distributions. Looking on their website right now
I see of course Debian Ubuntu, Fedora being three of them but also Arch Linux, Sabayon
and as well as Rell and CentOS. It is now been reported to be stable on Linux the ZFS
on Linux port is stable and Linux and is felt to be ready to use in a production environment.
I have been using ZFS on Linux for approximately one and a half years on my own home server.
Originally it was a Debian 7.0 based server that I was running the XFCE desktop environment on.
However I recently have switched over to Ubuntu 14.04 mainly because it's a long-term support
release as well as it seems to work very well under the Mate desktop which is of course a
re-implementation of the GNOME 2.0 series of desktop environments and whenever I first started putting
together a server back in the day. I think it was in the Ubuntu 10 era that it originally used
GNOME 2. So it has worked very well thus far. I'm using like said Ubuntu 14.04 with the
Mate desktop. It is not the recent re-spin that was put out with Ubuntu 14.04 with Mate I added
the repositories separately. However it seems to work very well the way I've put it together
haven't had any issues with updating or anything like that. ZFS is I do feel the final say in file
systems. It is robust. It has copy on right protection. It basically treats multiple discs as
one large pool so the nice thing about that is if you have you can set it to be basically for
high fault tolerance if you lose one disc assuming that you've done it correctly you will still have
a file system and going through commands using command line you can actually remove the faulted
disc and put it back and put a new disc in its place. You can set it up to be similar to
RAID 5 or even RAID 6. So basically you can lose one disc or two discs and you've still got
a working file system. Now the one thing to keep in mind is that ZFS is not a substitute for a backup.
While it does have snapshotting which I forgot to mention earlier which basically means that it
will be able to make a snapshot in time of your file system and you can go back and retrieve files
that may have been deleted. These are not backups. There is still nothing that can replace a backup
let's say to another computer to a USB drive or even to something like crash plan which is an
online backup system that is compatible with Linux as well as other operating systems including
Windows and OS X. There are even some guides on certain distros that show you how to make it your
root file system. Now on my server my root file system is still EXT4 and I use the ZFS as
sort of the area to store audio files, video files, family pictures and things like that.
Before the brave ones among you out there who would like to try something like that I believe
that Arch Linux actually has a guide on their website to show you how to do that.
Now out in BSD land there are ways to and I think that there actually is a natively supported
file system so it is supported that you can install that to a root partition and use that as
your main file system. Now I have had a few problems with the ZFS and I should restate that it's
actually not a problem with the ZFS it's problems with certain hard drives. My current server setup
is 5, 3 terabyte hard drives set with a fault tolerance of 1. So basically I can lose 1 drive
and maintain the ZFS pool. Now I ran into an issue where I lost 2 drives at one time and therefore
my ZFS pool was gone. I was not able to use it. Luckily I had all my files backed up
on another computer and didn't have to worry about that. However it is something to keep in mind.
One idea if someone is going to put together a pool such as this, a ZFS pool is to get
drives from different batches. So basically I think it's a bad idea to buy all your drives at one
time. It might be a better idea to get them from various places, Amazon, NewA, Tiger Direct
or even a local business if you're lucky to have one nearby that would be able to sell you a
driver to and you'll probably have better luck than I had with that setup. Now I don't want to
jump on one drive for being more reliable than another drive or company be more reliable than
another drive or another company as far as hard drive manufacturing goes. However there is a
website called Backblaze, B-A-C-K-B-L-A-Z-E.com who they run a multitude of servers in their company
and they actually did a drive life study inside their company and the results can basically be
found out on their website which I will place in the show notes might be something to think about
when you purchase a hard drive for your for your rig. So I just wanted to let everyone know
about the ZFS file system. I know it's been discussed before on Hacker Public Radio.
Keep in mind this is my first podcast that I've ever recorded so I'm hoping to do some more
in the future and I've thought since I do listen to quite a few HPR episodes that I might as
well contribute as well. And also before I go I just wanted to thank JWP who did a ZFS file system
podcast on Hacker Public Radio's HPR number 1600 on September 19, 2014. He had some very good
information about the ZFS file system and especially about reasons why it is not included by default
in Linux related to its licensing issues and he has a very good handle on that. So I recommend
you to go back and listen to that podcast as well. Once again thank you very much. Look forward to
doing something like this again in the future.
You've been listening to Hacker Public Radio at Hacker Public Radio dot org. We are a community
podcast network that releases shows every weekday Monday through Friday. Today's show, like all our
shows, was contributed by an HPR listener like yourself. If you ever thought of recording a podcast
then click on our contribute link to find out how easy it really is. Hacker Public Radio was
founded by the digital dog pound and the infonomicon computer club and it's part of the binary
revolution at binrev.com. If you have comments on today's show please email the host directly,
leave a comment on the website or record a follow-up episode yourself. Unless otherwise status,
today's show is released on the creative comments, attribution, share a light 3.0 license.
