Episode: 377
Title: HPR0377: Future of Artificial Intelligence in Open Source
Source: https://hub.hackerpublicradio.org/ccdn.php?filename=/eps/hpr0377/hpr0377.mp3
Transcribed: 2025-10-07 19:24:18

---

You
The following presentation from the Utah Open Source Conference held August 28th through
the 30th, 2008, is underwritten by Central Point. Providing the ultimate Open Source Server
solution makes IT simple, manageable, and affordable, www.centralpoint.net.
Streaming and podcast hosting bandwidth for this and many other presentations at podcast.utos.org
has been provided by Tier 4.
The presentation was given by Benjamin Payne on the future of artificial intelligence
in open source.
Thank you.
Let's see if I can get this thing going again.
Cool. It's always great when things work.
Just a little bit about myself. I guess we can start the start.
My dad was into computers. I kind of went into the family business, I guess you could say.
He started when I was nine years old. I wanted a computer to play video games on, video games at the time.
I wanted a computer and he was like, sure, there's one in the basement, go ahead and take it.
I went down there, there's nothing down there but parts everywhere.
I was like, there's nothing down here, there's no computer. He's like, yeah, put it together.
It's like a puzzle. I broke a few parts here and there, but I eventually did get together.
That led me swiftly, I'd say, into programming where I used to write those old text-based multi-user dungeon games.
The mods were way popular back then. I enjoyed doing that and kind of just catapulted me into programming.
Since then, I've been trying to be around computers as much as I could.
When I was 17, I was a lead IT guy for engineering company in Heber City called Epic Engineering and they did just civil engineering based glue.
That was really interesting, difficult, I think, because I had engineers that were asking me to come fix their computers and I was just a kid.
So I did that.
Shortly after that, I began working at a company here, I don't know if you've seen it, it's down to Sandy.
It's called Cadence Design Systems. For them, I was doing grid computing and we wrote software that controlled the...
It was like a meta software for the grid for server farms. We were automating build processes and it was really cool because we were able to take huge build processes that would sometimes last days and we could get them down to 10 minutes.
So I really enjoyed that and I started school at Utah Valley State College where I'm still at for a couple of semesters and then I'll be done.
So that's pretty much me and now for what you really came for.
First of all, the topic that I decided to discuss was the future of artificial intelligence in open source.
I'm going to kind of intermingle that with my presentation here. The presentation itself doesn't cover a lot of that and it's mostly about how to do AI.
But I think that there are a lot of applications that could be used that this specific stuff can be used for.
As you can see, I've said that there are different types of artificial intelligence.
That is important to mention because a lot of people play video games or other things where they hear of the term artificial intelligence.
That's kind of different than what is actually academic artificial intelligence or the research artificial intelligence where the mathematics hit the road.
I mean, it's different in a lot of ways and I'm going to show kind of how both of those work or that's my intent.
So let's go ahead with that.
There are a lot of different areas that the artificial intelligence is being used in.
Like I said, games is one, but that's a little bit different than what we're going to be talking about.
Working on things like learning medical records and for instance, just imagine if your house could do statistical analysis on your energy use and just save you a lot of money on power and gas and things like that.
That would be super awesome. Also, they're using the artificial intelligence to see how people use an application or online.
What are you interested in? You can just look at what you keep browsing for and it can send you advertisements based on that, trying to get you to buy stuff.
Unfortunately, the field of artificial intelligence hasn't progressed quite like they planned it to do.
When it first started, it was just kind of this awesome field that people were like, we can do anything with this.
We can just use this thing in skyrocket and we're going to make computers behave like humans.
That's still, I guess, the overall goal, but it's not progressed as people would have imagined.
But there are a few places that it's done very well in. Like as you can see, speech and handwriting recognition, both of those can be used or can be done with a neural network, which is what I'm going to discuss a little bit later.
Also, data mining is a good field that artificial intelligence has been really successful with.
If you're not familiar with that, it's basically where you just grab all this data from either a database or the internet.
And the AI will grab out things that seem to be relevant so that a person can look through there and say, yeah, this is good.
This is not spam filters can be artificial intelligence underneath the hood.
I put in simple that YCRC is in here. The reason I did that was just because I have an example that kind of illustrates exactly how that's done.
So we'll take a look at that a little bit later.
This is my first type of AI quote unquote. This is your game AI. This is the basic level.
If any of you have studied computational theory at all, they go really heavy into this.
And if you're familiar at all with regular expressions, this is kind of the exact same thing.
And it's pretty interesting because you could use a string if you wanted to.
Okay, this is happening in my game right now. This is happening and just start throwing out these things into a string.
And you can use a regular expression if you want to parse through that string to see what exactly you want your entity in the game to do.
Let me just explain how this works for those of you who may not understand at all the computational theory.
This here is considered an accepting state or a state where we're going to act on the behavior that we've seen or act on the information that we've seen.
We start out here in this state and every time we get a piece of the string, like if B comes in, if that's the first thing I see, I don't do anything.
I'm still in that state. As soon as I get an A, I can move over to this state.
Now, once I'm in this state, if I get another A immediately, that's fine because I will just come down here.
I can take as many B's as I want. And why is that relevant? That's a balanced question.
I mean, I'm trying to think off top of my head what might be a good example.
Can somebody give me a good popular game that I might know about? Just off the top of your head.
Alright, let's say it's half-life because half-life is from what I understand. I'm not a big gamer, but from what I understand half-life is first person shooter.
Okay, let's say, for instance, that I'm here in this state.
I see an enemy player run across the screen, then I'm going to move to this state.
Then, if the enemy player goes behind a wall or something like that, then that's going to move me around this B state.
It's a different event that triggers a different type of response.
Once I've moved around this B state, then once I get in contact with him or as soon as I see him again, that's going to give me another A state.
Because I've seen him. That was the first day. He went out of view and then I've seen him again and then I'm going to have the AI go ahead and fire at him.
Does that make sense?
Alright, I have some code here written in VB. Again, my apologies.
It's helpful if I have an internet connection.
Let's see, I'm going to go ahead and try and connect.
Should've realized that.
Bear with me here. That's alright.
Do I have to log in?
Yeah.
Okay.
Oh, that's right.
Sorry about that.
Okay, we should be good.
Alright, I'm going to stay back here so I can get a good look at the code just for a minute.
Sorry.
I've actually commented out a lot of the code in here just because the state machine that I was explaining earlier is the commented out part.
I just last fall came back into this code and didn't change it to another language because I was too lazy.
And I implemented what's called reinforcement learning.
I actually have that.
I mentioned that earlier. We'll probably get to that if I have enough time.
So we'll see what happens.
It's kind of complicated stuff.
Anyway, what happens is this is a tick-tax tail application.
And what it does is every time the original player, the human player, makes a move, it will call into this function where it will run this AI.
And you can see it's pretty simple.
I mean, it's going to check for the win right here.
You know, do some really simple logic.
And then it's going to jump into checking for its opponent win or the human to see if the human's winning.
And once it's finished with that, it's going to call into this move maker thing.
And that's honestly, it's really that simple.
It's just checking for different states and then making decisions based upon them.
Now, I didn't do this in the sense in the exact sense of a state machine.
This is really just hacked together code.
But it could be a lot more poetic, I think, if I did it the other way.
But obviously, that's kind of, I don't know, if that's all I thought of AI, I think I'd be really disillusioned by the whole idea.
Because all of this is just code making decisions based upon states.
And whoever wrote the code, they're the ones making the decisions.
It's not learning at all.
And artificial intelligence is all about learning.
Now, I'm just going to go ahead and warn you that in order to learn, you have to do some statistics.
And if you combine statistics with kind of abstract math like discrete mathematics, then you start to get into some interesting results.
These are the types of learning algorithms that I have played with.
As you can see, we're going to go over kind of how to build a neural network.
And if, if I had time after that, then we can talk about reinforcement learning.
Hopefully we can get to that.
That's some pretty interesting stuff.
Unfortunately, I don't have any slides for that.
But would anybody have any problem if I drew that up on the whiteboard?
Can everybody see the whiteboard, all right?
Yeah, if you can't see, just let me know.
All right.
Here's my beautiful drawing.
I'm sorry I have no artistic ability whatsoever.
As you can see, this is kind of what a neural network might look like.
Right here, we have our input values.
That's where all these four along here are.
These lines represent the weights.
The way is basically a numerical representation of like a type of variable into the statistical algorithm that we're going to use.
What really happens is the value that's put into here, for instance, let's say it's binary.
We have a 1, 0, 1, 0.
Simple enough.
The value in here is going to get multiplied by each one of these.
And it's going to go into these, we call them hidden states.
They're just basically plate holders so that we can feed forward.
The reason to have these hidden states is because if you go straight from the input directly to the output, sometimes it's difficult for the system to learn.
And it's even possible for the system to learn exactly backwards of what you're trying to get it to do.
It's not very helpful.
It's really boring.
And you might even think that you've done something completely wrong and you might be discouraged.
As you can see, each one of these are going to have their input into the hidden states.
Now, once we get to this portion, what we've done is they've all had to save all of their input from each one of these input states.
They've had to save it into some kind of an array.
The reason why is they're going to have to take all that information and add it all together, basically.
So that's kind of where the algorithm gets a little complicated because you've got to move from here iterating through this set of states.
Now you've got to start iterating through these guys and you have to go through all of their saved information to add that all together.
Before you can run the exact same algorithm as was run here to get these outputs.
Anybody have any questions so far?
What's that?
Could you be a little more specific?
I thought it was being pretty specific.
What are you talking about?
One set of those nodes are input nodes.
It goes through, it proliferates through the neural network and what reaches the output node.
The output node is our actions, reactions, something like that.
That's correct.
I just want to look into the game.
How would those nodes...
This is actually that one that I talked about.
That's more of a state machine kind of thing.
This is actually trying to learn something.
It would say that you statistically hide there more often.
Does that make sense?
Now, if I can maybe give an example.
I kind of thought that originally.
It's similar if you...
You don't calculate if you take the limit as something approaches infinity.
If it's a specific kind of function, it will either converge or diverge.
This function was written to converge at some point.
If it converges quickly, then we've got these weights that never change.
If we hard-code those weights into here, then we've pretty much got a state machine.
But, you know, they're always going to change based on the user input.
Does that make sense?
If I could maybe give an example.
Like I said, if we used binary functions throughout these inputs.
We were trying to get, let's say, an output that had...
That was a cyclic redundancy check.
That was one bit or two bits.
In this case, two.
If we input our bits that we get into here.
They're going to multiply through these weights, get to these hidden states.
Then the hidden states are going to multiply by those weights.
And it's going to make a guess.
The guess that comes out is going to be a fractional value.
It's not going to come out and say one.
It's not going to come out and say zero.
It'll say like 0.98 or whatever.
Well, I've been close to once.
We just round it up.
You know what I mean?
What I did in my neural network was I took all the values.
And if it was 0.5 or above, I just went ahead and rounded it to one.
And if it was below that, anything below that, then I just rounded it down to zero.
So anyway, let's continue on with this.
Here is my extremely beautiful representation of how this is done.
Lots of nasty math in there.
Basically, you take the state value, which is x here.
And you take the weight value, which was calculated by the back propagation
algorithm that we're going to discuss.
Now, in order to get this little function here, we, I don't know, it's kind of hard to see.
But basically, we take, we have a variable n here.
It's probably really hard to see.
And we start with i equals 0.
This is a for loop simple.
And all we do is we take our value in the array that we have to multiply it by the value for the weights.
We have two arrays, right?
The exact same size, both are of size n.
And we use our for loop to iterate through there.
We add them all together.
Pretty simple stuff.
Then, once, then that gives us this variable that we call net.
Once we've got that, in order to get the output value, which you see here,
all you have to do is take the inverse, or one over the one plus this e value,
which is the base of the natural log.
And, raise that to the power of the negative of net.
That's really, it's a tough explanation to get.
Does anybody have, like, an easy way to explain how that works?
It's like functions in math, or even functions in C++.
I'm presuming that we have everyone at least understands what a function is.
Basically, each one of those nodes, all it knows how to do is one thing.
That's right.
Take all of its inputs.
Yeah.
It does that one thing to them, and it spans its all of its output.
That's right.
And it uses this net as kind of the intermediate variable.
It's a variable as an input to the function.
That's just my function right there that I'm using.
And the reason it works is because I've actually drawn a graph here.
This is supposed to be kind of a mathematical representation of what the graph would look like.
You have your axis, your x and y axis, and it's going to converge as it goes out to infinity.
So, as I run this neural network training algorithm that I'm going to be showing here,
as I run it over and over and over again, like seriously, probably 100,000 times or more, you know, but 100,000 is pretty good.
It'll start to come out with the values that I'm actually looking for.
So, on that one before this, you'll start to see the 1 and 0, if that's what you're looking for.
You'll start to see things like that.
I have some code which might...
Sorry.
That's fine.
I just remember something about Monte Carlo's simulation.
It's a little different than that because it's based on this underlying statistical thing.
What happens is, this is only the forward propagation, right?
It's called a feed forward because all of these inputs get, you know, going to that function and come out of the output.
Now, when I first start, it's obviously going to be wrong.
You know, it's making these random guesses to try and come up with the output.
The difficult thing is training it.
What happens is, they call it a back propagation algorithm because as all of the information feeds forward, it comes up with a guess.
And the guess is going to be wrong the first few times, probably the first 50,000 times even.
But then what I do, and we'll cover this in just a minute, is say, no, it was supposed to be a 1.
And then that sends information back to update the weights that I was talking about, the little lines.
And that information starts to crunch down to the point where it gets, you know, so it's different than Monte Carlo.
I can give an example, imagine watching football for your first time.
And then the beginning of football games, you're pulling the guess which people win.
You're probably going to get it wrong.
Right.
But you're going to learn something great.
And after you've watched it without a football game, you're going to have a pretty good idea of what team you're going to win.
Yeah, and see, your brain is actually a lot smarter than a computer.
So, you know, it's going to pick up on certain aspects a lot quicker.
You'll be like, well, that guy's not a very good player and, you know, so you're going to pick up a lot quicker on that.
And the reason why is because of what you're using to learn.
In this case, all we're using to learn is a bunch of bits, one or zero, fed into this neural network to try and get whatever comes out.
We're not, we're not learning anything really specific, you know, there's no mathematical algorithm that we're putting into here to say,
okay, if you get a one and a zero, then you're going to want a one to have a odd parity.
Does that make sense?
Everybody know what parity is?
If you have, if you want an odd parity, you want an odd number of ones in the system.
So, if you have a one zero one, there's currently an even number, so you'll say one there.
If you have a one, one, one, you'll say zero there because you already have an odd number.
Does that make sense?
And that's what we're, that's kind of what I'd like everybody to imagine with this neural network is,
we're putting in the one zero one or whatever, and we want it to give us the value that comes out.
It's a really, really simple, simple thing for a neural network to do, but it's really, in my opinion, a good, good, basic thing to learn from.
So, is everybody good on this? Can I move on?
Sorry if I'm being really confusing.
There is a problem with this stuff, and it's, the reason that I highlighted this is because it was really important.
If you just set in a lot of information into a neural network, it's probably not going to learn it.
It's got to have kind of a pivot point or a bias that it can look at to see what it's supposed to be doing.
Kind of like an anchor in a boat, you know, it's got to have some kind of foundation.
If you work here, it says the summation starts at zero, but we have an x state starting at one and going to four, so obviously we're missing something.
Like I said, this is the anchor state that I was kind of talking about. It just kind of helps the neural network to update its weights more correctly, and it's going to converge a lot better, whereas the other one might not even converge at all, without that pivot state.
I've seen here because I have a trouble with art, and I want to tell them, you know, if they see this real human being, even though it's art, it's going to tell us it's sandbox that it's doing it.
I don't know if anybody else on that global level, or it's all just making sense.
I'm probably like more on the other side where I'm just like learning how, like, trying to figure out how to build a more intelligent artificial intelligence.
That's true.
There's sort of an AI war going on here. We've got the increasingly intelligent and network, and we've got increasingly intelligent fan filters.
The thing is, the outside of getting the good might have to get better war for a single war.
That's right.
It very well could be. Like I said, neural networks and things like that are used in data mining, and a spam bot is just data mining gone bad.
Okay, and if I can enter them, whether or not the spam bot is really art, the point of spam is usually to get your personal information or get something out.
That's right.
I've heard of the Russian meaning box. There's a box in Russia right now that will perfectly emulate the lonely moment, and it will talk to the guy.
And it is so human life that will convince the rest of the human to the point where they can give out their personal information.
He probably wrote it.
That's right.
So you can't talk to it if you're in the United States.
Anyway, I think maybe if you understood how an artificial intelligence works, maybe you could figure out how to not train it.
The problem is, bots like that are usually similar types of artificial intelligence, and they're not looking for you to train them.
They've already been trained.
They're just out looking for information, and they're collecting it all and shoving it into a database.
Is this not interesting at all?
How does that relate to AI, though?
This is just how to implement, how to write the library, not really how to use it.
So I actually do have a pretty good, let's see here, this is all really nasty math.
So for those of you who care, you can go to my website and grab this off if you're more interested in it.
I'm just going to go ahead and skip to something that might be a little more interesting.
This was an idea I had about six months ago, I would say.
I was at work, I worked at a home automation company, like I said, and they have a microcontroller that runs Linux.
And you can get into the microcontroller, they have a guest account, it's useful for the dealers, the people that sell our product to be able to get into there and compile scripts and things like that.
Sometimes the feedback from the embedded system is just not what you're looking for.
And so sometimes you honestly need to get in there and compile a script.
While I jumped on there, the operating system guy was refusing to give out passwords and the guest account didn't have a password.
So fine, you can get in, right? So the guest account really can't do much.
So I wanted the root password, and I was trying to get it from him, he wouldn't give it to me.
And I thought about the whole thing was encrypted with des. I don't know if any of you heard of that.
It was an older version of des. It was like the eight character passwords, you know I'm talking about, it just truncates it.
Or you know it fills it in with blanks.
Or I was like, you know that neural network that I was showing you, I was like easy.
I just break it up into a bunch of different states like that.
It takes the hash that comes out of des.
You've seen the little thing with a bunch of different ugly characters coming out of there.
Yeah, if you ever looked at your past WD file at all, well it's not in there anymore, but obviously embedded system it actually is because it's kind of an older version of Linux.
But if you look at the past WD or the shadow file in your Linux box, you'll see that there is a little hash.
It looks like a bunch of garbage, like capital letters, lowercase letters, numbers, all the way through that whole thing.
That's what they call the hash. That's what gets created by when you type in your password, it goes into the program and out pops the hash.
So my idea was to grab the hash out of there, which the guest account had access to for some reason.
I think that might have been oversight on his part.
So I built that neural network that was showing you, and I took the hash, and I actually had one neural network for each bit in the whole entire ASCII thing.
So if you do the math, it's actually quite a bit. Because there's like eight bits in a byte, right?
One byte can represent one ASCII character, and there's eight ASCII characters possible.
So it's like 64 different neural networks running all at the same time.
And then I take my hash that I took out of the past WD file, and I take that and I shove it in to this neural network, or the set of neural networks.
And I took that over and over and over. Basically what I do is I had a driver program that was running, and it would grab a word out of a library.
So I had this huge library with like hundreds of thousands of words in it.
It would take a word out of the library, and it would encrypt it with death.
And then death would return the hash. I would take the hash, feed it into my neural network, and it would propagate through, and then once it had gotten through there, then it would make a guess.
And obviously, you know, it's going to be wrong at first. But what I did was I just took that original word that I used to encrypt, and I said, no, the word is this.
And so it would take that run through that back propagation algorithm that we kind of skipped over, and it would update all the weights.
Eventually, it got to the point where it could guess accurately what the password should be based on the hash.
And I ended up getting that I passed his hash into there and came up with the password, and that was the correct password. It took about 14 days to train the thing on an old 900 megahertz processor.
It was actually, it was pretty funny because I had used, have you ever heard of John the Ripper?
It's a ripping, yeah. I used that, didn't come up with anything. I ran that thing for weeks, and it didn't work at all.
So, I ended up being 46 with a space, and then the word vomit. So, it was pretty interesting.
So, I went and told the guy, I was like, hey, I'm counting out what your password is. He's like, how did you do that, and I explained the whole thing to me. That's kind of cool.
But then he said, I didn't realize that the guess could see the hash, and I was like, well, I'm sorry.
That's kind of like one way that I've used it. But you can see from that story, that it's really important to define what you want.
What I did was I decided to break the whole thing down into ASCII, right? So, that way ASCII is easy, because all it is is just one bit per character, and one byte per character, and the bits are easy to break up.
So, that's why it's really important to define your features really well. A feature is actually defined as the unit of measurement, kind of like in physics.
You know, you've got the worst, and here we do it like in pounds. So, in artificial intelligence, those are called features. I don't know, okay, most of that, actually.
We talked about building that training program that I used. I took the words out of the library, and I fed them back in.
I'm actually currently working on a project that's kind of on the same lines as what you were talking about, what it does is it goes in.
And if you've seen those, I don't know what they're called, but they're little pictures. So, you can look at the picture and determine what it's supposed to be.
But see, I don't ever use those things. But that's already been done. Yeah, but not by me. That's why it's interesting problem. You know what I'm talking about? Anyway, but see, I don't use them for anything. I just like to see if I can do it.
It's kind of that. Yeah. In fact, we're my professor and I, the guy that I've been doing research with, we're actually thinking about that. The difficult thing is, how do you run the back propagation, which takes a lot of computing power, while you're running the game, which takes a lot of computing.
Most games, yeah. We were thinking you could have like a server side, and then you could have a client side, right? And the server side is separate from the game server. It's a AI server.
And what happens is, every time something happens in the game, it takes all that information, shoves it into the AI. That thing runs the really nasty calculation, which takes memory and processing, like lots of iterations on the processor to do.
But we think that that's possible, and we're actually working on a project to do that. You can, did you say through the video cards? Yeah. So you're talking about using the GPU to compute the thing. Yeah, we've actually looked into that a little bit. It's kind of cool because you kind of have to break it down into a graphic.
I mean, that's what you submit to the GPU is a graphic, and that thing can crunch numbers like nobody's business. You know what I mean? So that's kind of a way that they're going yet. We've looked at that too. That thing's really awesome. It has Apple, PowerPC processor, that is the main processor, and it's got a bunch of IBM processors running underneath it. It's got eight cores, I believe.
Yeah, things are awesome. So.
And let's real time feel already applied, because in non-nural network AI, all of this factory thing is usually done a little in adjustments on consciousness and a function in the forensics.
So what they do a lot on games, stuff like that, is they adjust the characteristics of your AI ahead of time.
So the AI gets smarter and smarter. But that only adds momentum to the process, right? It speeds it up. You still got a lot of crunching to do though.
It only adds momentum to the neural network process. It causes it to convert faster.
Yes. Well, I was talking about using the forensics in non-nural network.
Okay, yeah. With like reinforcement learning, or something like that?
More like path searching, which is much more common in the game.
Yeah. It's true.
Yeah, like it checks AI. Often times we use tree searches, like decision trees. That's what we're talking about.
And that relies literally entirely on it.
On heretics, right? Which takes a lot less computation, but still a lot.
Well, considering you've got to say before, I think you were bored with different kind of moves.
Right. On chest, your heretic is a rotation.
Right. That was a big blue or a deep blue?
I'm actually one of the chest tournament.
Uh-huh.
You have to build your heretic into a hardware and then you go fast.
Right. Exactly. And so that's the kind of problem. We're trying to make it so you can use a regular machine, a regular PC.
That's what we're working on right now to build.
Yeah.
And it does the computation for you.
Thanks for that because I actually, you know, I'm about like, I'm trying to take the knowledge that I know and come up with something a little more nucleus or whatever.
Right.
Thanks. I appreciate that.
But if we're going to pull it back up.
WECA?
Yeah.
Treatment?
Cool. So there you go. Now you have a library.
Just API, plug it all in.
That's, that's way awesome.
Because I was, you know, I was going from the ground up and saying, okay, this is kind of where I think things are going to go.
I didn't really get into that, but.
But, uh, yeah.
You can keep training it if you want.
Well, how do you do that if you're working on the real data without?
You run the back propagation algorithm that I was talking about.
Kind of skipped over that page. It's on there. It's on AI.tricks.com if you want to look at it.
But you don't have to run that.
You have to know the answer, right?
Right.
Okay. So if I'm running this neural network on this dog of data, it comes up with something.
I've got no way to back train it and say, oh, that was wrong or.
Right.
So you've got to be pretty, you know, you've got a narrow your domain of the things that you're looking at.
And be pretty sure what you're going to get in there so that you can train it appropriately.
Because you don't want to grab in something that's clear off out in Timbuck, too.
I don't really know the answer to the stuff you train it with.
That's right.
But you don't always have to train it.
Does that make sense?
You don't have to run the back propagation.
You can take whatever it gives you as an answer and trust it.
So.
Right.
But.
That's right.
Like with back.
The domain is well defined.
You know, if the range of stuff that you're looking at is pretty well defined and you know kind of what you're going to be getting out of there,
then you're going to be pretty accurate when you get it back.
So.
I don't know how to make the network and how long to train it.
The network, as many inputs as you have for data, that makes sense, right?
You want about two times the...
What I usually do for an algorithm is multiply the number of inputs by two and subtract half.
Does that make sense?
Two times n and being the number of inputs minus one half of the number of inputs.
Does that make sense?
So you're going to get like if you had two, you know, two times that's four and minus half you're going to be back to two.
Well, you could, but it's going to be different for different numbers.
Does that make sense?
Actually, you'd be...
Yeah.
Sorry.
I think I didn't do that, right?
Yeah.
Well, that one point five.
Anyway, the reason I do that is because you want, generally, you know, two is a very small neural network.
Now, generally you want like a little bit more hidden nodes, hidden states, then you have input states.
So you multiply n by two and then subtract it by n times 0.5.
That makes sense?
Two n minus 0.5 n.
Which gives you 1.5 n.
Right.
We'll do that.
Okay.
So you have one point five times the same hidden states that you give input states.
Right.
So you have more.
I don't know.
How did you make it?
I'm saying what, man?
My calculus class?
Nobody understood me, so.
Don't feel bad.
Anyway, I think of that time.
So I appreciate you guys bearing with me and coming, listening.
Thanks.
Thank you.
Thank you for listening to H.P.R. sponsored by Carol.net, so head on over to see R.O.N.C.
Thank you for listening to H.P.R. sponsored by Carol.
Thank you for listening.
