Episode: 1264
Title: HPR1264: Open Accessibility: Interview with Steve Lee
Source: https://hub.hackerpublicradio.org/ccdn.php?filename=/eps/hpr1264/hpr1264.mp3
Transcribed: 2025-10-17 22:40:49

---

.
.
Hello everybody, my name is Ken Fallon and today's show is an interview
and the presentation Steve Lee gave on accessibility at our camp 11.
That's correct over one and a half years ago.
I'm not even going to bother to attempt to apologize for the delay in getting this show out
without further ado, I give you Steve Lee.
Hello everybody, my name is Ken Fallon and welcome to the
I'll camp 11 again, I'll camp one month. I'm here with Steve Lee down the
base, but Steve, you're going to be given the talk today.
Yes, I am, straight after lunch, so I'm hoping everyone will be a bit dosy,
but hopefully the coffee will have kicked in.
Oh yeah, I might be awake, but it's...
So what's your talk about?
It's going to be about open accessibility, so there's an area I've been interested
in a long time. I guess my main interest is the benefits of open
development that they can bring to users specifically for people with
disabilities and allowing them to access technology in innovative ways,
which suit them. But there's actually a much broader picture
than that in that the making sure that technology is available for as
wide a number of people as possible means that we can all personalise
this stuff for the way we want, which is something someone was talking about
yesterday. They want the system. There's a discussion about unity
versus going through a typical one, but there are people in different camps,
but it boils down to people wanting to use a system in the way that they want
and accessibility if you take it in its broadest meaning.
Definitely.
Yeah, it allows you to do that.
When people say accessibility, it's such a broad range.
What sort of areas are you focusing in on or is it just accessibility?
I'm going to give a brief overview of what accessibility means.
Some of the options are available in operating systems, particularly
I'll be showing you Ubuntu because the audience here will be happier with that,
but I use it as well. And then looking at some of what's called
assistive technology, which is more technology, but it's
actually interfacing in a more extreme way.
The typical example is a screen reader where someone is completely blind.
They can move around with a keyboard and what's visually available on the screen,
which they can't see, is turns to text, so they can understand it.
And I'll be showing some demos of some of the great open source stuff that's around.
I know a lot of the people listening to the Hacker Public Radio network
will know that we've had some shores on accessibility in the past,
and Ubuntu has had some criticism about the move to unity
and how accessibility was seen as a secondary issue.
Do you hope to address that?
I wasn't intended to, I was probably going to gloss over that,
because it was the only limited time. Yes, you're quite right.
If you look at the history of when I first got involved in open accessibility,
there were two communities heavily involved with Gnome,
who were really doing a lot of work to make sure that Gnome desktop was fully accessible,
and Missilla, who were making sure that the browser,
because when you think about Web, there's a whole stack, and I'll be covering that,
but everything needs to be accessible, all of the bits, so I will need to work together.
So Gnome 2 had a lot of effort put into it.
And when unity came out, there's some of the stuff got moved around,
and accessibility stuff got dropped out.
So I think it will come back in, I hope it will.
The accessibility team in Gnome have changed.
KDE was sort of the other alternative.
They were starting to pick up on some of the technology.
Now some of the mobile platforms are looking at it as well.
So I'm hoping it will improve, but yeah, I'll leave it at that.
Yeah, I know, I definitely see it as a winning point, a sales point for the free and open desktop.
If we can get that together, then by default, it's a requirement for the other operating system.
So if we clean up our house by extension, the other houses are going to have to clean up as well,
so that's only a good thing.
So have you had a chance to see any of the other shit talks here?
Yes, I was very interested in Karen's one, who's actually now the CEO of Gnome.
So I didn't realise, I'm a bit out of touch at the moment.
I knew Stormy quite well.
And that was really interesting, because you were saying early,
it's nice to have something a bit left-field.
And her talk, completely left-field, she was talking about very open,
saying, I've got a pacemaker, and I want to know what software is running on it.
Can you tell me?
I don't know, went to a manufacturer or couldn't tell you that.
And that's worried.
That brought in a lot of issues about your rights and the very personal notes as well.
And it is slightly accessibility, I think, as well, using technology to improve lives.
So that really interested me.
Okay, I'm not going to go delve too far into your talk,
because it'll be on this network anyway.
But Steve, thanks very much, and hope you have a good talk today.
Brilliant.
Thank you.
And now, on the main stage, we have Steve Lee from Oktoberactive,
who's worked at Mozilla, and done some stuff with No, Have You,
as well?
Yeah, and he's going to be talking about accessibility in those and sorts.
Thank you.
Oh, that's good to see so many of you here.
Right.
Yeah, so I'm on the moment director, where you can't be able to just set up
a self-embrace guy, who is a boss watch, the high education advisory service of open source.
My specific interest is open accessibility, and has been for some years now.
Does those draw power?
Well, anyone want to put their hands on it, so what do they think accessibility means?
Oh, I'm sure he's on one.
I think those extra new ones.
Be named twice.
Yeah, okay.
That's a good one.
Yeah, big, big, then we think of it in terms of giving access to people with disabilities.
And that's an important issue.
There's legal and moral reasons that you shouldn't exclude people.
I'm going to take a slightly broader view than that, though.
That's a very important part of it.
What I'm going to say is accessibility really is making sure that technology is useful
by more people in more situations.
In other words, a new development can only be developed.
Any hands?
No, there's a few.
And the rest of you, I guess, are the users type to that right?
Okay.
So we can develop some software.
You obviously want as many people as you use it.
There's certainly no open source you want as many people as you use it,
because the users they can become contributors.
So the important point is, when you design some technology or some software,
don't you think about that?
Is to put the users first.
Think about the users.
Not the technology.
And what that actually means is you may get to a universal design, inclusive design,
and user-centered design.
That means you're thinking about what the users are going to do,
how they're going to interact with your software, rather than the blame,
which is more fun, you know, technically.
And as I said, normally accessibility is considered specifically for people with disabilities.
Now, there's a lot of disabilities in brackets is that disabilities are really
the result of how people react to them, by how you design a software,
it's experienced somebody.
That makes them disabled.
Not the fact that they may not be able to see very well, or hear very well.
The other issue is that most of us are aging.
Well, sorry, they're age-related issues.
I know I'm aging.
That's about the rest of you.
So I'm going to find out why I saw something as good as it was.
And we're in a different rapidly, really longer.
There's also, at the other extreme, because there's going to be children using technology as well,
and the way they interact with it is different.
And there's also a lot of people that are situational disability,
that become more known now because of mobile technology.
But, for example, you might be in a noisy environment,
or you might be in a very bright, sunlit environment.
So that effectively causes the way that you interact with something.
You need to change the way that you react to something.
In general, there are four areas of access that you need to think about,
when you think about how people interact with technology.
There's hearing.
Now, the most computer technology is visually oriented.
So if you have a hearing impairment, that is not such a big issue.
If you have sight impairment, the same reason means you have a big problem.
And then the other side of that is how you perceive the information
that say technology is giving you.
The other is how you interact with it.
And some people will have physical disabilities.
As you get older, there's our fighters,
but there are people who have very limited movement disabilities.
And finally, there's cognitive.
Which is basically how you process information.
You'll be finding a lot of people who say you're learning it,
but you're finding it quite hard.
If there's lots of stuff going on the street at once,
and there's stuff flashing around, that just causes an overload.
And interestingly, if you look at the list there,
there's pretty much the same in order
of how well people are supported through biotechnology.
So people with hearing difficulties,
that have a huge problem,
but people with cognitive difficulties often have.
I'm underservedly right by the word that's going on.
The other issue about the people is the context here.
And one of those context is the actual person you yourself.
How do you interact with the software?
Is it important?
And interestingly, some people are looking at the patterns
of how people use the mice, the mouse,
to identify who they are so they can do context.
People are way person.
Personalised advertising.
So the user's a context itself.
But there's also the environment here.
If you're in a car, you can't interact in the same way
as you would do, and this is nearly desktop.
And there's actually device itself.
There was a little tiny screen of the little phone.
Lots of our phones.
That's quite different to the big desktop environment.
So because mobile is really bringing a lot of this stuff to focus.
Where's accessibility?
Two years ago, you really purely do think about people's disabilities.
It's now becoming some of the issues that you need to think about.
And designing something to be accessible to as many people as possible.
I'm also coming out of the mobile design.
For example, the form factor is varied.
If the text is really small, it's hard to read.
If the target's for you to touch a tiny, it's really hard to do it.
So you've got the fact that it's like mine.
Also, as I keep saying, you use it in different environments.
And you move around with your mobile device into a noisy power,
into bright sunlight.
Also, new ways of interacting are coming out.
So now people quite familiar with touch screen.
Whereas before I looked on the project,
where touch screen was used for people to dimension
to give a nice simple, big button touch screen interface.
But now we're all getting used to that.
And as the lot of design knowledge could be coming into how
to design interaction patterns that use touch.
So I'm going to show you some examples now of some of the features
that fans desktops have.
I'm running Ubuntu here.
But all of your pages have these.
There's a simplest features.
There's no more tweaks that you can make.
So, there's only luck.
So, I've turned on this icon up there.
You don't get to somebody else, but there's some little options
that are in here.
For example, an obvious one is make the text larger.
The text has got bigger.
There's another one.
Press your keyboard and shortcuts on the time.
Now, to bring up a system menu on here,
I press the old and the space together.
And it up comes in the system window managing menu.
Talking to Windows technology.
But if I press that one,
if you can't press two more than one here,
at once I can now press the old followed by the space.
So, these little traditions of all of them
in all operating systems.
And you won't even think of them as actually
as a accessibility option.
For example, if I go into the system settings
and we look at,
oh, it's funny, there's a screen store.
There you go.
So, you go into the mouse.
It's the very first one.
It's kind of right-handed.
So, is that an accessibility option?
Well, you could say it, I don't know.
How did you turn the icon on the indicator?
I think.
It's pretty sure.
There's a whole bunch of snuffing there,
which isn't on the body phone.
I can't be used to these new store bars.
Is anyone actually used to it?
I thought I'd turn on the option to make this thing.
So, it isn't accessibility issue, obviously.
I think it's in this one.
I think it's that one.
That, as you know, it was a whole chunk of technology.
I believe it was on of a cover in a minute.
But I think that's on as well.
I think that it's not.
But, yes, it's been left handed.
It's disability.
Well, some people might say,
it's my wife would be annoyed if I told her she was.
But the point is, it's an adjustment.
If you want to use a mouse in your left hand,
you want the buttons to swap around.
So, that's some very basic and themes.
Most people are aware of things.
There are high contrast themes,
which have a big difference between the text and the bandwidth.
For people who have difficulty seeing.
So, that, there.
Oh, if I can get rid of that.
Hello.
I'm going to have to stop here.
It's a pretty nice screen, isn't it?
Oh, I did pretty good.
I didn't realise I clicked on it.
I didn't feel it.
Use that option over there.
Right, it's just to avoid even more confused.
Oops.
Right.
So, there we go.
That's some really basic options.
Another thing you notice is I'm using the keyboard.
A lot of people like to use the keyboard.
But if someone's been designed just for mouse access,
that's the other problem.
Right, I've got the one one up there.
I think.
Is it closed everyone?
Oh, there it is.
Right.
So, there's another thing here.
Personalisation.
And I noticed that in the panel section we had before,
because there's been a debate.
I want Unity.
I want Unity.
I want Unity.
People want their own options.
And you all, I guess, set up your best thought.
I mean, something we don't have to use,
we're going to use its comfort.
We all tend to set up things that were best for us.
So, there's this concept of personalisation.
And all these things I've just shown you.
You could say that personalisation is just the fact.
Well, I'm going to start off with a big degree.
It's, well, I can't actually use imputed the technical tools.
I don't really think anything.
Or, I'm a bad guy, I'm going mad,
using the buttons throughout the long way.
So, what's important is the use of Unity interfaces configurable.
And what's even more important is you want Unity configurable
on all of the devices that you use.
And what would be even better, and I'll show you something else,
and I hope you can do this eventually,
is that your settings would follow around from your iPad
to your bungee desktop, to your television,
that they would move around with you.
Right. Now, assistive technology.
I've only heard that term before.
Yeah, okay.
Well, the actual fact, I mean, everything that,
aware of assistive technology is technology,
actually do something.
In medical terms, it covers everything from wrap, wrap,
as they help you get into the bath,
to highly complicated electronic technology.
What I'm talking about here is,
the stuff I'd show you is just tweaking the user interface.
Some people, in some situations,
you want something more complicated.
And they actually adapt the user interface
into a different way of working.
So, a very common case,
which people are now becoming aware of,
is text-to-speech, where the speech is spoken out for you,
and voice recognition.
That's becoming almost mainstream now.
Most systems have some sort of,
a low-rise do-surf,
it's sort of a Google map,
so I can speak the destination,
and I've done a lot of stuff, and I enjoy it.
For blind people, it's quite an extreme case,
because they can't see anything.
There's people who are completely blind,
and nobody's in it.
There's something called a screen reader,
which allows it to navigate around the contents of the screen,
and it converts it into speech,
the reason, so that's an assistive technology.
For people who have really,
a bit of physical disabilities,
there's on-screen key.
You're probably used on-screen key,
but it's not a photo touch interface,
but traditionally,
I've been used before,
for people with physical disabilities,
particularly those who are very limited in their motion,
and all they can actually do is just twitch a bit,
so I'm going to switch here,
and you might not be able to do that.
Stephen Morgan is a good example,
all down he's got a switch,
it's not regular way,
twitching is cheap.
So you need something that converts that single action
into the ability to tie,
and I want to be able to do that,
and I'll show you an example in how they work.
It's very tedious and slow.
So that's how you see examples of that now.
So the first one,
and probably the one that,
because the blind community,
for a long time,
there's a lot of them,
and they're very vocal,
and they lobby hard,
and so they get a lot of attention.
And so,
a lot of the initial accessibility to work
was for screen readers,
for people who are actually blind.
One of the interesting things about that
is it's one of the harder problems.
It exercises a lot of the requirements that we had.
Now,
do you know,
the Glenn Projects,
have an accessibility group,
and they increase in the almost screen reader,
and I'll show you that.
I think it is built in,
and I don't think that you can get this out of the repository,
so that you...
When all just screen readers are marked
with higher frame,
preferences button.
Okay.
So a blind person would typically navigate around the screen
using the keyboard,
so our...
It's button.
Oops.
Wrong one.
Tab.
About button.
Exactly.
So if you notice,
it's any more key,
I press Tab again,
and they're more...
What it's landed on,
it's not actually that clear.
Can you see the focus rectangle around the bottom?
So that's the object that has focus.
Tab.
Help button.
Okay.
So...
Tabs go back to preferences,
but we don't...
Tabs go back to preferences.
Tab, speech page.
Tab, tab, tab.
Tab, tab.
Tab, tab.
one readers are divided into different numbers.
Then, we read слats,
you may write...
So if i title it again.
and infrastructure, and it's a little bit of a bonus.
So, each page, the bulk of references,
each page person,
including one of the setting was called combo parts.
It's not to get confusing,
because as you move around,
it's just like saying stuff is slow,
it serializes everything,
whereas you look at everything and random answers,
it detects it, serialized, so that you do find
that blind users using incredibly fast,
and they like synthetic voices,
because you can go really fast.
But longer than just a cheek now,
I'll just apply that.
I'll apply that, or kill over a city, free-loaded,
or kill communities.
No, it's like, if it's a cyber accent there.
That's...
The other thing we're talking about is...
A metal.
OK, molten.
No, I can't see where I'm at.
Leave it to the top.
Stage, page.
Right, now I can move.
So, it's on the top.
So, you get...
It's on the top, isn't it?
Right, you can't get it to the top, babe.
Magnify a page.
It ain't called magnify a tip,
or it's not a tip.
So, it should have had that point for a minute, babe.
Tilt.
Right.
Now, let's have a round.
Ah.
So, ah.
Let's move on.
Let's move on.
So, someone, very low vision, this is quite useful.
Now, I've got a try.
OK, your factor.
It ain't called magnify a tip.
So, it's a tip.
Right.
So, there you go.
A lot of people need to use this technology
in order to interact with computers.
Right.
Oh, that's a good idea.
Oh, just read, read, complete, torture.
That's a big bit of it.
He's not quite.
But if you sing that, you're...
Right, OK.
Now, that sounds good.
It's one of the reasons I'm interested in open accessibility,
is the chances of innovation.
That actually has been around a long time.
It's an alternative way of entry and text.
And you actually just need two gestures, really, up and down.
And the idea is you steer your way through some letters
to try to text.
So, we'll show you.
You'll be able to see it.
You'll probably be freaked out by this.
But, um.
That's just bringing that up.
OK.
So, let us down the left.
And that will change as I move through it.
And as I move through a particular letter,
apparently, it had the text field at the top.
So, I'm going to do this very slowly.
So, I click to start.
I'm going to move slowly.
So, I'll let it go.
I'll move left and right.
There's a chance of speed.
I mean, notice it's got prediction.
So, it's guessing.
I've got a really easy after.
Here's the word prediction.
And why is it loose?
There we go.
Something you always had to say.
OK.
Right.
Where is it?
But the point is you can actually steer.
I saw someone make a game round for this.
Where they have a switch that went round you.
Do you bring your theme that was up?
Do you bring it down?
Do you bring it down?
It was down.
So, you mentioned text by controlling your image.
But this is a program.
There's lots of versions.
There's another version that you can control with just your arms.
So, that's an open source project.
It's always been an open source project.
There's no proprietary equivalent of that.
There we go.
Let's go outside that one.
Another one, this is good fun.
You'd like a can.
And for people who are physical disabilities,
who can't use a mass of people, this is very useful.
I don't know if this will be to work.
So, this is a head tracker.
So, it picks up the camera.
I'm going to do it.
What's that?
So, I'm moving my head left to right.
Couple of times.
There's a lot.
It's too dark for it or something.
It's not.
That's controversial, isn't it?
I think the controversy over there,
is it the HP webcam that couldn't be text?
Not quite people.
All right.
Is that the same problem?
A lot of the world.
Is this the lighting conditions?
Right.
It's really not going to work in there because it hasn't.
This one wasn't new, but I had to deal with it.
So, it's not going to work really well.
You can see the points in there moving around.
And then if I want to run something like the hell.
I love that.
That is calibration.
Right.
You know, because I didn't click.
I just, well, something called dwell click.
It's one of the options I showed you at the beginning as well.
You can't click.
You can pause.
I mean, it doesn't click for you.
It's an asset.
It's an asset for the hell.
But I'm going to get out of here.
Good fun.
Right.
There's a lot of options at the top.
You can dwell on those buttons and change.
There's a very left kick.
There's a very right kick.
But it's fine.
It's easy.
Yeah.
That's an easy one.
Let's go to the bigger button.
Oh.
Let's go.
I thought.
Look.
The bigger button is the screen.
Yeah.
I think it might be a good idea.
There we go.
Then let's try and do this live.
It has got.
Ah.
It has got off.
I've got.
Wait.
No, it's still there.
Okay.
One more drop.
It's quite an old pre-kick, you know, the program.
The going one screen keyboard.
There's a version on board that comes with this.
But the point of this one is, again, it's for people who
just use these switch devices.
And it has a mode called scanning.
And the idea is, is that things automatically slept.
It was various ways that we'd done.
And when it's at the right point, you activate the switch.
So, no, I'm not even using the switch.
I've got it set up to use the left and right snaps button.
So the left button will start the scanning.
And the right button will...
Can you see that?
It's right down below.
Can you see that?
Can you see that?
Can you see that?
Can you see that?
As you've already got it, I see it's going on.
It doesn't really.
So I'm going to press the left button.
So it starts the scanning.
A whole row at a time.
It's this wrong way.
And then...
A brand new one.
And what it's done.
It might actually be clear.
It's had to look around and see what's there.
It's created a menu item.
And...
For dashed, for client hand...
He's looked at the desktop piece, and he picks up the various options.
So, we'll start scanning again.
Which would be the safe one to run.
It's here to...
Left.
Now it scans left to right.
And...
I go for it.
It's not scanning again.
It's not...
It's a go for it.
Oh, there.
It's coming.
So if you like...
This grid is active.
It's a bit...
An overlay between the user interface and the switch.
And it means that some of the user's got very limited gestures,
can interact with each other.
But, of course, it's slow and...
I'll work.
So...
How many do you have at the time?
At the time.
By the way, very good.
Lost it.
20 pass.
Right in the paper.
Let's start the time.
50 seconds.
That's the scan.
I can put it there right now.
So you get...
You don't have to get out of it before I go.
Oop.
Okay, side of it.
Ah, there we go.
There's a quick there.
All right, so it's getting done.
There's a little bomb row over there for us to quick.
Ah, there's a bit of that.
Something's not quite...
There's a key.
Sorry about that.
Not the dock user.
The trouble with dock is it got very old and creaky.
Very...
That's it.
Got it.
Now, let's get rid of that.
Okay, so that's the presentation.
Oops.
Okay.
So, now, that's the desktop.
I just want to show you something quickly for videos.
I just want to show you a quick clip and stop it.
We all use technology every day.
A person at a library computer.
A person using a mobile computer.
A person buying a train ticket.
And we're using it to do...
Right.
Okay.
I hope you saw that.
Did you know anything about it?
Yeah.
So there's a couple of things going on there.
We'll play it again.
We all use technology every day.
We all use technology every day.
A person at a library computer.
A person using a mobile computer.
A person buying a train ticket.
And we're using it to do more.
Okay.
So, if I play the game, turn off the sound.
Which would be the case of your death.
Or if you're in a noisy environment.
That's a sound tone.
Hopefully, you can still make some sense of what's going on.
Okay.
Or, don't do it the same way.
D F and D.
A person at a library computer.
A person using a mobile computer.
We all use technology every day.
A person at a library computer.
A person using a mobile computer.
A person buying a train ticket.
Okay.
So the point is, when you couldn't see it,
if there was something going on in this library,
there was two technologies there.
Close captions were the text at the bottom,
which was designed for people who are deaf.
Sometimes, close captions are the same here.
I mean, actually, they're slightly different.
And there's audio description, which is someone who's blind,
when you can see it.
Or when you're in a great bike sunlight.
Which is technically what was going on in the screen.
And there's actually a very interesting reserved open project
called The Universal Subtitles,
which is sort of crown source.
The idea is you go to a YouTube video
and you add these accessibility features to it.
Right.
We're going to open accessibility now then.
So let's give me a flavor accessibility later
and the options that there are.
Well, the interest of me is open accessibility.
And why I'm interested in that is because of
what open development potentially brings
to users of assisted technology.
We can talk about freedom and equity
and cost before people spoke about it yesterday.
And that's sort of a big part of it.
There's something really interesting I think
is the possibility of users being involved
in getting innovations that they want.
We've opened development that you can't get users.
And there's obviously, traditionally,
there's a whole debate isn't around where it is
just suitable for non-technical people to be involved.
But certainly can happen.
The other thing is speed and cost development.
There's an awful number of what are called
pre-cation devices.
I showed you that on the screen keyboard.
There's devices, which are basically
over there trying to be on the screen keyboard
and the best buttons and it talks to you
or helps you communicate with some of those.
There's loads of those, hundreds of them.
They've all developed things from scratch.
But there's a common shared library that people use
that development would happen quickly.
And innovation further up could happen.
There's also an infrastructure and standards
to allow this universal access to appear everywhere.
And finally, as mentioned,
there's absolutely involved with Geloan and Mazirra.
And one interesting thing about both of those communities
are acting as a hub for accessibility activity.
Geloan on the desktop introduced a lot of the technology
which other people are interested in.
And Mazirra will be doing it for the web as well.
And the two obviously need to go together.
Now, I'm going to get teching out with Mazirra.
So those are on that technical.
It's really important to log off for a second.
But there's something very important called
the accessibility API.
So an API is there's some mechanism whereby, too,
it's a software that can talk to each other here.
We were in a known way in the contract.
But the accessibility API is a way that
some external software can look at the user interface.
And it does a number of things.
It allows it to explore the interface
and see what buttons and menus and things are around.
What states and see what the user is doing at the moment
has the user press the button and gets a notification of it.
And also to do the reverse, actually,
control the user interface.
And this is vital to something like the screen reader.
You may not have noticed it.
But when I was tagging around,
when I moved to different buttons,
the screen reader was getting told that one of the focus
had moved to another button.
And also could go and look at the buttons to see
what they were, find out what text to speak to the user.
So this is a critical component for me for assisted technology.
It's also absolutely absolutely brilliant for testing.
Testing user interfaces is something that's really different to do.
Because they're very afraid of what they change very often,
it's a parallel problem.
But you can do regression testing to make sure
that your button hasn't been removed or a menu item hasn't been removed.
You can create some automated tests.
And there's a couple of projects within the desktop testing project
and DomTel, which are quite a lot of known ones,
both with the user assisted technology APIs to actually test the program.
In terms of open APIs,
it's just the APIs.
The good only thing that makes one,
ATSBI is, was historically,
probably one of the better ones.
It had been richest features,
and they had assisted technologies to find out the most.
And then it was ported to Windows.
To give the same sort of features.
Does that at the time,
the thing on Windows,
we don't necessarily have a very, very primitive,
wouldn't let you do much at all.
Windows is simple,
that's something to do with the UI activation.
Interestingly, this is an open standard that I like accessible to,
rather right away.
And it's actually managed by the Linux Foundation.
So it's quite interesting,
there's a Windows standard.
Managed by the Linux Foundation.
It's also an Android, there is one,
but it's very, very limited to its own.
Just to give you a little diagram,
of the sort of stack of technology,
there's the platform at the bottom,
the algorithm,
and the operating system.
And to get through the user,
the user,
a library interact through some accessibility options,
provided by actually desktop services.
Or are they using the system?
The idea has to go for the API layer.
Now, as one of the important parts of this,
is the UI tool hits,
which is producing technology,
provided by the in-genome terms,
in-genome terms,
I don't know if you can answer that,
but it's a GTK.
And that provides services
for application developers to put the various widgets
and tools in,
and also provides accessibility.
So I've just got quickly shown you what,
it looks like.
Give it a look.
So there's a little problem called accessizer,
which allows you to explore
the user interface,
as seen through this API.
There's a slightly different view.
Get down here.
So,
what I'm going to do,
is,
let's close it off.
So we've got something to look at.
I'm going to run G80,
because it's a nice, simple program.
And it knows you've got,
it's got some images.
As you know,
it's as far,
I think far, there's open,
so,
now,
by,
oops.
Sorry, excuse me.
I had this all sorted out,
and I didn't know.
Now, everyone has accessizer.
Basically, it just displays everything,
so it's just a higher up.
You know,
we look here on the left,
it's showing you all the applications
it knows about.
So down here,
there's G in it.
And I can do various things,
I think,
explore what's in the interface.
I'm going to look,
that's,
let's say,
I want to look at the application interface.
Now I'm sorry,
I'm not on a発.
I want to actually look
at the interface.
Now,
there's G edit object,
or the application,
it exposes,
no, no, no,
it's going down,
it exposes various things
that you can do.
So this is the application.
Well,
various things that you can do, oh sorry about this, it's strong, I think I can drill
down, so G-Edit has in it, an object which is not very interesting, but the one I want
to get to show you is there's the file menu, there's the file sub menu, and you can see
before it's flashing up red just to indicate where you are, but what are we going to show
you, so this allows you to develop it, to look around on the application and explore
it, so it's really a techie tool, the one thing you can do is a bit of fun, if you look
in the file menu, although it's not visible on the screen at the moment, I can still explore
it, and there's an item there called new, now the new thing has an action on it, click,
and it will perform it, and what's going to happen now is this program here, it's remote
controlling G-Edit, and we'll bring up the menu, it says, that's it, so it was, it was,
I was doing new stuff, it's supposed to be open, yes you quite a lot, thank you, open
there you go, so this works out for the open menu, thank you very much, so there's a G-E
tool which wants to show you that, right, fine believe it, there's a lot of activity
with web accessibility which is good, a lot of noise about it at the moment, I haven't touched
on that, that's quite deliberately, but we need to just cover it a little bit, the one
of the important points is W3C's activities and standards have always been accessible,
it's always been inclusive, and basically originally it was up to you, the user agent to decide
how to bring the information in the best way for the user, but because the browser needs
to understand him, to implement most standards properly, and also web developers obviously
need to use the standards in such a good way, but the web browser has quite a hard job,
which is why visitors work, it's been important, and that there's lots of nighting implement
the web standards, but also the platform standards, like the API's, but one thing that looks
very interesting about this is web apps, or web reaches, the even Windows 80's looks
like it's going to be webbing, but it looks like these are the technologies to look at,
and we're in the open directory, we're quite interested in it.
One of the advantages of this is they deliver a widget you can run on a mobile phone,
you can run it on a desktop, then you can take that, so they're a chunk of user interface.
So they're good in terms of their reusable components, and they can encapsulate good practice,
so some of them creates a really good, accessible, usable widget for logging, say, that's a very
simple solution, then that can be reused by developers, and there's a project we're
involved with, really in contact.
Just to show you context, if you're going to use to do all of that, I'm inserted the
web layer into this stack between the user and the platform, and suddenly you've got
these different APIs, you've got user interface toolpins, which are useful, and I can't
let them accept it.
There was a platform, I think, which is coming off there, coming up maybe with a mobile
space, so that you can access the camera or the georocation, and you've answered the
widgets, that they can encapsulate all of this technology in best practice.
If you are a developer, I've just had a few pins, put the users at the center of your
design, that's quite a cool thing, and testing, aren't you sure if you're testing with
a wide range of users, including people with disabilities, and don't make assumptions
about the user interface.
It's so easy to assume that when you're writing that, say, it's a web page, there's a
simpler, but you just have an on-click hand, but someone's tagging the keyboard, it's
not going to work, so it's very easy to make assumptions about that, and use the best
practice, and particularly in the mobile space now, progressive hands, and all this awesome
design, becoming the buzzwords, but they actually bring in accessibility best practice as
well.
If you use talking, so the point is, if you've only run widgets, but it's on the desktop
or in the web, then you've got to do with accessibility work, but if you use a stock widget,
it's provided by GTK, or provided by J-Berry, or Dojo, or something, then that hopefully
has had a lot of work done, I don't know, it will work, and also after giving you a
bit of experience, you can use it very friendly, just let you know, things are finished now.
Well, an event coming up at the end of September, I'm very pleased we've got three accessibility
talks in there, we've got Mark Eze, who is the accessibility guy, he's coming on to
just about working in a larger ecosystem, how it works, and Neil Williams, the Tony
Church, who makes devices for blind people, with little communications devices, and Julian
Martin, who's really great, he's working on mobile stuff.
One of the things he did was post a little daisy radio for Android, which is great, and
we decided we'd really get together, and this little device here is an Arduino, we've
sort of asked about a shield, it's the built board on top, so it's a standard Arduino,
and it's got a Bluetooth board on top.
The point is, you can plug in a switch like this, and when you click the switch, it talks
over Bluetooth to an Android phone, and everyone wants to see, I'll show you this, an Android
phone has got a special on-screen keyboard, which you saw at Scanning, it will do that,
and it responds to your question of switch, just as I was a question of switch is here.
So that may have somebody who's physically disabled or say a wheelchair to actually control
Android applications without using the touch screen, and I think, and then Julian's
too going to be talking about that.
That video that I showed you, and I think about time, I just finished off with that,
and knowing we're coming mobile and the web's becoming everywhere, and there's this needs
to make sure that accessibility isn't everything otherwise, it would just be one or two things,
and this project GPI, the global public, and inclusive infrastructure, is built on open
source, and the idea is to build an infrastructure which all the house, this personalisation information
if you want to call it that, to be carried around from device to device.
We all use technology every day, and we're using it to do more things all the time,
some of the things we used to do face-to-face, we now do with automated systems, for most
of us, those systems are okay most of the time, and when there are problems, we can
find a way to get along, but those of us with disabilities often run into situations
where the technology doesn't work well enough to meet our abilities, in some cases we
can use assistive technology to bridge the gap, assistive technology or AT can provide
text for speech, video chat with captions, turn text into speech, or make words on a screen
easier to read, whatever the user needs to accomplish a task, unfortunately we don't all have
the assistive technology we need, and we can't always take it with us to use anywhere
we want, imagine if you could pick up any device anywhere and it would automatically
adapt to you, imagine someone who is usually confused by technology, now every computer
looks like their personal device, simple, with just the controls and features they need,
complicated computer screen changes to a simple version, imagine a student who has to use
computers in different labs and classrooms, if all of them worked exactly as needed,
student in two classrooms, each computer becomes accessible as she needs it,
there's a way to offer accessibility solutions to more people in more situations, we call it
the Global Public Inclusive Infrastructure or GPII, the GPII will use the cloud, the electronic
networks that power most of our information services, and the intelligence and electronic
products themselves, cloud and server symbols and dotted lines show information clearly,
right now we use the cloud to store information, transmit it to the right destination and convert
it from one form into another, the GPII will take the same cloud idea and use it to support
accessibility, users will start with a wizard that helps them choose how they want their
personalized interface to look and work, and store that profile in the cloud so that it's
available from then on, accessibility developers will create tools for the toolbox that address
those needs, the GPII will store information about devices, their uses and features, then when
a user needs an accessibility feature, the GPII will take the right user profile and features,
check the device and guide the device and using its own features to meet the user's needs,
accessibility information flows through the cloud to the phone, its green changes to large green.
The GPII will automatically apply the right tool to whatever device the person is using, wherever it is.
So, is it that that's, it sounds simple doesn't it, but there's some huge technical problems there,
and if it's a big ask, if it's successful I think it'll be a real game changer, it's done.
Some of the concepts have been rolling around for a long time, but there's a year of game project
being funded to implement some of the components, you know. I'm going to stop there,
are there any questions at all? Yeah, I don't know.
So, one question, when were you showing the documents? When you were showing the various tools
or what you wanted to do, for example. Is there not a better way to do this, which would be
actually to produce a distro for people with blonde or visibility issues and a distro for people with
motorism rather than trying to put everything into the same package? Yeah, okay, there's no
issues. Most people, we talk about the people with disabilities, that they don't necessarily want to
use a special tool, they want to use the same thing that all their mates and friends are using,
so on the desk not, they want the, you know, to use everyone to, or the mobile phone, they don't
have that clunky. You know, remember those blue and three-wheel vehicles that used to go around,
we used to go move things and it's gone, but that's one issue.
Another issue is that these programs are going to develop very many, so they might have
might have all been there. There is one issue that's been content for a long time, is that,
that API I talked about, it needs to turn them on and it can have a speed impact on everything
that's going on, so by default back is off and it's been a long time and you better have it on
because it gets tested more by everybody who tests and develops it, and I don't think it's
important to the problem now. Another issue is that people need, some people, what non-necessities
set up, so there are people who want to be able to install and run Ubuntu from scratch, with no
vision, and there is, I don't know what the state of it is now, it got very close to being possible,
because it means you need to get it right back to the start act and make sure it's all accessible.
However, having said that, there is a guy telling me to say, oh, he's creating three ideas,
which is a distro specifically for people who lack digital impairments.
So, I mean, tools is for courses really, but there's a lot to be said for having the
stuff in there for anyone to use. Potentially, they could be useful for other things,
like that head tracker thing could be useful in someone I can't think of,
so what do you know about the state of voice control systems in junior labs?
Not much at all, but a voice is an issue. The control I don't know at all, the text entry,
which is like a simpler problem in some ways, there is a number of, there's something with
Simon's, Simon Edissons. I mean, as far as I can find, there aren't any finished tools
that are on the frameworks, since I'm going to play with Simon and see a new experience as well.
Yeah. You've gone through the massive important course here, so it's very important.
It's actually just, is it, is it?
It's been a no-week experience for ages, and the trouble of Simon Edissons is to get that
specific recognition bit, you have to, it's licenses, that's a crudgy way where they can't
redistribute it, so here is a user who can go with their own website, that way they can store it
as a separate component, which is a real thing. So, it's not a problem in good news and
so it's one of the fun.
Do you have any eye track of my software, because obviously the money is out of dachshund?
Yes, of course. Yeah, I haven't put one on here.
I think there's a version of dachshund, I was going to have a quick look at that,
so I don't know. It's a hard problem, hard of the head tracking one.
I'll find out for you, because I was wondering that.
The commercial systems, if you look at them, for people with disabilities,
there's something called my toe, it was a big one, and that was initially developed
from marketing, so looking at where people, when they see a website, where they look,
you track their eyes and work out where the hotspots are.
And that has an app, and that then, they thought, oh, this would be useful for people,
physical disabilities, you can't use a mouse or keyboard, but the prices are something
like 14K for this PC, basically, which is picked up and connected on the bottom of this,
but in Paris. But there is the opening, which I haven't seen, there's a line, there's a really
good open source project, which the Viacam is based on, which is all the visual image manipulation
and tracking, and there are various positive look around that they've done things like,
they think you can recognize icons of their photo, so people can control the computers by
holding a yellow circle or a red square as a gesture device.
I was going to say, as a follow-up on to your point, I saw a project by,
I don't know if it was a year or two ago, about 50 research laboratories,
using OpenC Vehicle Directors, they wrote this specifically for a friend of their
locked-in syndrome, and then they'll call that process that an inference adapted.
Was that the last one? Yeah, I could read you off.
Yeah, as far as I know, it used OpenC Vehicles, it could be pretty easily adapted to use an
on-screen keyboard. Yeah, that was a really good project, wasn't it?
Let's say, another project, a lot of good accessibility solutions weren't like that,
there's something for someone specific or a specific issue, because they've become more genuine.
I was also wondering, as a way I was able to look inside running out, get access to that,
what is that underneath, and can we get it? Yeah, the value of accessibility is
A and B alright, which is exposure and information. Now, what has happened is all of the in-built
controls, like buffens and menus, and the true objects in TDK, they expose that they've been
written so that they expose that information through that API, and this is one of the issues
if you've created your own ones, it doesn't work. If you want to play around a bit, look for
Pi ATSBI, which is a Python library, which makes it really easy to use, so it's PY ATSBI.
I also have a little bit of dog toe on there, holding deep bits, I think they're both
Python, and they're both userat. The greatest mechanisms into it, I've got users in really
anti-wise CVase, it's one of the problems we have in here, so I have to appreciate it.
Okay, any more questions?
I want to say a new record, any questions are interested in any aspect, so you please answer.
You have been listening to Hacker Public Radio at Hacker Public Radio. We are a community
podcast network that releases shows every weekday Monday through Friday. Today's show,
like all our shows, was contributed by a HPR listener like yourself. If you ever consider
recording a podcast, then visit our website to find out how easy it really is. Hacker Public
Radio was founded by the Digital Dog Pound and the Infonomicum Computer Club. HPR is funded by
the Binary Revolution at binref.com. All binref projects are proudly sponsored by LUNAR pages.
From shared hosting to custom private clouds, go to LUNAR pages.com for all your hosting needs.
Unless otherwise stasis, today's show is released under a creative commons,
attribution, share a like, lead us our license.
