Episode: 433
Title: HPR0433: Demo or Bust 2010 Part 3
Source: https://hub.hackerpublicradio.org/ccdn.php?filename=/eps/hpr0433/hpr0433.mp3
Transcribed: 2025-10-07 20:29:13

---

music
The time once again is 8.30 you are listening to WART radio, which means it is time for
our DemorBust 2010.
The time once again is 8.30 you are listening to WART radio, which means it is time for
our DemorBust 2010.
WART radio, which means it is time for our DemorBust 2010.
WART radio, which means it is time for our DemorBust 2010.
WART radio, which means it is time for our DemorBust 2010.
WART radio, which means it is time for our DemorBust 2010.
WART radio, which means it is time for our DemorBust 2010.
WART radio, which means it is time for ourTEYAN.
Watch out!
Why why?
Delivery!
Delivery!
Why why?
Watch out!
Why why?
Delivery!
Delivery!
Why why?
Hello everyone and welcome to the third edition of Demore Bus 2010.
I'm going to say really quickly that the aim of this program has changed a little bit,
where it was narrating a personal project of mine in just writing a demo.
Maybe that's a little bit boring, right?
Instead we're going to be interviewing people generally and talking about demo stuff and computer stuff and 3D stuff.
But before we get into any of this, let's listen to some chiptune music,
because chiptune music is awesome.
This is the first time I've ever played this kind of music.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
I've never played this kind of music before.
That was Sorcerer's Battle by our friend, Bird Cothman.
During the last block party, he performed this live.
We had such a fun time dancing.
There's no tomorrow to it.
I've lost my necklace during that episode.
It was a lot of fun.
This particular song is really heavy on the FM synthesis.
I just want to tangent for a bit.
FM synthesis being kind of a favorite technique of mine.
I'll explain it very briefly.
It is two waves.
It's a wave whose input frequency is modulated by another wave.
Typically, these are sine waves.
If you have a sine wave, modulated by a low frequency sine wave,
that kind of sound.
You get kind of a sort of sound from that.
The theory is that provided that you have an infinite domain of frequencies
to choose for these two oscillators,
you generate kind of a, once they get passed,
sort of a night-quist frequency, you generate these harmonics.
And the combination of these harmonics, you build a foyer system
so you can recreate pretty much any wave.
That's the theory behind it.
But in actuality, you don't have an infinite number of frequencies to choose from.
They made up for it by making it fuck-o-complex.
Typically, FM synthesizers have different algorithms,
what are called algorithms, of different oscillators that are put together in different ways.
Let me play really quick, very briefly, from a panel
that for did at BlockPretty 2008, in which he describes FM synthesis.
You should watch it, but this is a quick audio clip of a ramp up of a one frequency modulated by a frequency that is ramping up
to give you an idea of what it sounds like.
So we'll be right back in like two seconds.
Now an interesting thing happens.
I'm going to have a first vibrator real fast so you can see it going all over the place.
I always saw it down.
It's a very simple oscillation.
Now I'm going to speed it up.
And I'm going to continue speeding it up every so often.
So you can actually, this is going to make some transformation.
You see the waveform starting to take shape there?
It's no longer just a sine wave going back and forth into complete sound.
Now we take away the vibration and it's just a simple sine wave.
And then we put it back.
Now it's a complete sound.
And it's most basic form.
Now all those little spikes that you saw there, those are side bands.
And it's still not actually a concrete waveform, you know, a single sound.
All right, I'll do it again.
Actually, I have more visual aids coming up, so you'll get to see those.
I'll run out of time if I go back and forth.
Do it again.
I like that person.
That was kind of funny.
So we are going to be talking to IQ from RGBA, more or less specifically about ray marching.
And before we get into ray marching, I do want to discuss ray tracing because I feel that ray marching is kind of an offshoot of ray tracing.
And just as a preference, so you have an idea of what we're talking about.
So ray tracing is a technique for synthesizing 3D scenes on a computer.
On a 2D screen, have a 3D image.
And the idea behind this is that you can do this through light if you have a light source, for instance, in a world.
And you have a sphere and the light emanates from this light source.
And bounces off the sphere and is all over the place in this world and maybe bounces off a few other objects.
If the beams of light go into a lens, this lens sort of bounces the light around in my head.
I don't know the equation quite often, but it curves the light into a focal point.
And some are in between this focal point.
And the lens is a film or a retina or something.
And the idea is that the light that is intersects with this film is coherent from the lens such that you can generate an image from it.
And if you think about it, just like go for a walk or something and think about it.
And it's cool because all 3D can just be generated from light if that makes sense.
And so how you do this in a computer is very difficult because you can't really go from a light source to a film simulating this easily at all.
Because the lens will only intersect like less than 1% of the whole light in the scene.
So if you compute all the light beams that come out of the light source, you have to forget 99% of them a little bit more.
More so. And so that's not very efficient at all.
What you can do though is do this backwards because most of the equations for just the equations for bouncing light and optics and things like that just can be done either way.
So forget the lens. This lens thing is far too complex because the coherence to, well, the decochier image such in such a way.
To represent it how it was before it was adhered together by this lens is very, very difficult.
So instead what we can do is we can skip all this, forget the lens and project what are called rays out from a camera position being sort of the focal point of the lens.
More or less. Intersecting a plane, this plane being, say, a screen of 1,024 by 1,024 pixels.
And see you create these rays called vectors that start at your camera position, your sort of focal position and intersect a point in the screen where this pixel is.
And that kind of like becomes how the light would cohere in a lens sort of like it lacks a, it lacks an artifact from actually having a lens called focus which you can't really do focus easily in traditional ray tracers.
Of course they have evolved quite a bit over the years. So you have these vectors coming out and then you can do all the optics backwards.
So you check all the objects that are in your world and see if they intersect with one of them. If they intersect with the sphere for instance, you have this vector sphere intersection which you can figure out exactly where it intersects hydratically.
And then you figure out what the normal is of this object that you just intersected with. With the sphere it's usually the normal is just a vector from the point where it intersected to the center of the sphere.
And then you bounce it off this normal if the sphere is reflective you bounce it off and it just bounces off like light would be bouncing off. And you continue doing this until you intersect with an object that is not reflective.
And then you take the dot product of a vector from the light source to your intersection. And that becomes the amount of light that is present there that kind of simulates sort of the sort of the fading away aspect that makes sense.
So you have a light source that whose rays are approaching parallel to your objects normal. And that's it. So that's the technique. This has been practiced for a while and it's traditionally a very slow technique.
It's been sped up considerably but before I don't want to get into all of this by myself. I want to talk with IQ about this. So let's take a musical break as we always do and we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
And then we'll be right back with IQ of RGBA.
But let's see here. So you are a member of RGBA. And when did you join RGBA?
I'm sorry.
I didn't understand the last question.
Oh, when did you join RGBA?
When? I think it was in the 98.
Well, it wasn't we weren't called RGBA yet.
We were called Hennesseys or Hennesseys.
But later on we became RGBA. But we are still the same people.
So we first met in the 98. I think at university.
Now, are you all met together and from this group?
Are you a founder?
Yeah, well, I was there since the beginning, almost.
So yeah, yeah, yeah.
And well, actually today there is not...
There aren't many RGBA members who are active.
It's basically me. And then R3D, which is a modeler and we're efficient.
That's pretty much it because the other coders, they are doing other stuff like spectrum video games and things like that.
Or they went into the Linux scene.
But really making demos is just me and R3D.
We never lose the hope.
We are trying to convince the others to join and come back.
Are they impressed by some of the demos that you've been releasing?
Yeah, yeah, of course they are. But still I'm not doing good enough separately to convince them to come back.
I just like harder.
Yeah, so that's why in the last time I have been looking for people to collaborate with.
I see.
Working with people from other groups and so on.
And I think that's nice also because so far all the members of all the members of RGBA were Spanish.
And I think it's nice to make productions with people from other countries.
How many, just I curiously for myself, how many, how popular is this, how how many Spanish groups are there?
I don't know, it's explosive. That's about it.
We have maybe, you know, also propaganda, propaganda.
This was popular group in 2003, 2004.
Then in the old days in the 90s we had iguana, which they made third position.
I think at assembly a few times.
And today we also have, so we have explosives in this.
Then we have spawns, which are doing amiga.
Sorry, macintosh, the most mostly.
And then you have collapse, which are doing 4K, and then you have fusion.
Which are doing 4K intros also and they won't, I think they did second position on breakpoint.
Or even one, I don't know.
There are a few groups, but I think it's one of the times they don't show up in international parties.
They stay in Spanish events and competitions.
How many, how do you curiously, what Spanish parties are there that you've gotten to personally?
We have a huge one, it's called Eustal Party.
But in the north of Spain, normally it's gathers 5,000 people.
So it's kind of attempting things.
Not in Spain.
But most of them are not singers.
So the party was the most important in the beginning in the 90s.
Because now I think they are in the 17th edition already or 18th, I don't know.
But in the beginning it was pure amiga, the most important part is that it was PC.
And in the last year it was mostly for gamers and people, I don't know, doing all sorts of things.
And we only go then 20 demociners today.
Partly.
A huge party.
And then we have in Barcelona, we also have another party, a PCM party, which is only for demociners.
And we gather 50 to 100 people.
It's not a lot.
And then we have, in the best time, in the early, so in the 2000, 2001, we have like four or five parties.
It is here.
And that was nice.
But today we only have the first party, which is this huge event.
Not really the most in related anymore.
That's why we are starting now to go outside a bit.
So, if you don't mind me asking, what was the first party you've been to just in general?
Like, when did you first become aware?
You were mentioning, it sounds like you go back to the early 90s.
When did you first become aware of the demociners?
In the 90s, actually.
The same year I joined.
So, when I knew about democin, I said, OK, I joined this thing.
I like it.
Because I was already doing demos myself without knowing anything about demociners.
But demos, they weren't demos.
We normally say about demos.
They didn't have music and so on.
But I was doing effects on many algorithms.
And when I saw there were others doing the same thing, I said, OK, I'm going to join them now.
So, as soon as I knew them in the 90s, 97, I think, I just joined.
Yeah, it's kind of similar for me a little bit.
Just when I was growing up, I did a lot of sort of graphical things, at that makes sense.
And like little tests and demonstrations.
But I wasn't aware of demos or what they were.
And so, you know, had I known back then that's immediately what I would have done.
And so, I'm just starting to get into it myself.
I became aware of demos very recently, to be honest with you.
I think, in the end, if someone likes democin, they will find it in the end.
I think a few days ago, Gargai was saying, in one of the threads, that democin is destiny.
So, in the end, you are going to find it somehow.
Yeah, normally people, there is also some people that like programming, other like minifix,
graphics, but in the end, they will end up on the demos if they have to.
Yeah.
They will say, you know, there's things, or whatever, like games, or whatever.
Yeah.
It's destiny.
Do you mind if we take a quick break and play kinder painter?
OK.
OK.
Yeah, perfect.
OK.
Everyone, this is demo, right?
So, you've got to watch it.
It's not just audio.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Okay.
That was kinder painter.
The Piat ID on that is 26751.
The URL is HTTP.
Koln slash slash.
www.piao.net slashprod.
.php question mark which equals 26751. Now IQ this is a this is a GP ray tracer as I understand.
Yeah. And it seems like you have at least a couple of you at least have reflection rays going on
here. There's a couple of cylinders, a couple of spheres, a couple of planes.
Actually, this is a very typical ray tracing thing. In fact, it's called white ray tracing.
So, this is ray tracing as it was designed in the 80s. So, the very first ray tracer was doing
exactly this. So, sphere cylinders, planes with reflection and shadow rays and pretty matching.
So, no global illumination or ambient occlusion or block shadows, no motion blur, none of these
effects that are needed today to have a nice image. So, yeah, this is a very very simple ray tracing
as it was done in the 80s. So, it shows the typical primitives like sphere cylinders and planes.
No, you are just quite limited because in the 80s it was like whoa, but today no one is
impressed anymore by spheres and cylinders. So, that's why in the paint, in the painter was
my first experiment on the GPU and then I said, okay, we have to move along and do something
else and sphere and then the other production came. You are doing a bit of motion blur.
May I ask how you're doing that? Are you doing that with a motion buffer of some sort and
then blurring with that? But the real time demo doesn't have any motion blur.
Oh, really? Only the video that I recorded with motion blur.
Yeah, but the thing is that there is some of the movements on the sphere that are too fast
and when I recorded the video at 30 frames per second, the frame rate was not fast enough to
capture the movement of the sphere. Something rate was not enough because the spheres were moving
faster than at 30 movements per second, let's say. So, I have to run it with motion blur so that
you could understand that the spheres were moving. Hey, here that follows the truth is out.
I'm watching the video capture here. Well, you know, I don't have a very good card as far as
processing programs on the GPU. That's the problem of intros today. Most of the 4K intros
they are really abusing the GPU. Yeah. What do they? That's a pity. That one. What can we do?
Well, when did you start programming on the GPU? This is 2006, Kinder Painter is.
When do you think that this approach has reached? When do you think this was possible to program
just pretty much rasterizers of any sort you want on the GPU? When did this first start to appear
in the scene? Sorry, like, just to see when? Yeah, not. Yeah, one did, one did, we start to see
people actually start to write ray tracers and converters and other such things.
2006 or something. So, the main feature we were missing before to do ray tracing on the GPU was
the ability to do conditional jump. Normally, the GPU, you have to program the GPU to do your effects.
You have to put some code in it and the GPU. That's normally written in GLSL or HLSL
languages, which are similar to C, but these languages were very limited before 2006.
So, you couldn't do any statement and you need that to do a ray tracer because your pixel,
your ray either intersects a sphere or a plane or another object and then you have to choose
how you are going to shade or compute a normal based on which object you hit. And to do that,
you need an if. So, if I hit sphere, I do that, if I hit a plane, I do the other thing.
So, before we have the if, instruction on the graphics card, we couldn't do it.
And I think it was in the 2006 or 2005 with shader model 3 graphics cards, but we have this
ability. So, I think it was at that time when we started to see the first ray tracer and not only
ray tracer, but it was really an explosion of effects, not only on the ray tracer in field,
but everywhere, like post-processing effects, motion blur effects, texturing, procedural animation,
all sorts of things on the GPU, when we finally had the pixel shaders 3.
Okay. So, now a technique that's becoming more and more so in the Vogue seems to be ray
marching, which is in adoption of ray tracing, as I see it. Could you talk very quickly about
the just the technique of ray marching?
So, before I take this, I would like perhaps to say why we have been ray marching today,
and that's because as a kind of painter he's showing, with ray tracing you can only
intersect spheres and planes and cylinders, because these are shapes, which have very simple
mathematical representation, and that means that you can mathematically solve the problem of
intersecting your ray with this primitive. So, the intersection, the way to solve the intersection
is to a formula, which is known, and you just type the formula in the code, and you have the
intersection point. But if you want to go beyond spheres and planes, and you are lacking the
mathematical formula for your shapes, because what's the formula for a match room, or what's the
formula for a forest? So, then you have to use something else on ray tracing, and that's where
ray marching comes into the game a bit. And the techniques are like, basically a ray
marcher is just like a ray tracer. The way the lighting is done, the way the animation is done,
the way the rendering is done is exactly the same. It's only the intersection
computations that I replaced. So, instead of computing the intersection with formula,
do it in another way, and that way is what we really call the ray marcher.
What we have been here, basically, is to take the ray, which normally is used to detect
an intersection, and instead of computing the intersection with a formula, we just take the ray,
and slowly test in root force, if you want, like trying to find in a way somehow where the ray
hits your primitive. And that's done again, not by solving a formula, but by just testing.
So, basically, you take a point in your ray, and you say, okay, am I inside the primitive or not?
And if you are not, you take another point. And then you try again, okay, and now inside the
primitive, did I hit something? Just or no, if you didn't, you try again another point.
And so on until you find the point. And there is many, many ways to choose this point,
to choose how you test different points along the ray. So, the easiest is just to take one
after the other, like advancing in the direction of the ray, that's the simplest one, but there are
many other ways to do it. Like, you have the sectional methods, you have Newton-Rapson methods,
you have many, many ways to try to choose your points in an optimal way, so your chances to
hit the object are higher. But for four kilobytes, the most we are just doing the simple way,
which means you start in the origin of the ray, and you slowly step along the ray until you hit something.
The other pretty much so, it's a very overfull technique, because the primitive, the description
of the primitive, doesn't have to be mathematically simple anymore. It doesn't have to be sphere,
or a plane. It can be anything you want. You can invent any sort of formula you want, and then
something will appear on the screen, let's say. So, it's like you can't really model anything
you want. You just need to know a bit of formula, and mathematics, but not really a lot, and then
you can kind of sculpt the shapes you want through this formula. But you don't really need to solve
the formula. You have to write them, you just have to write them, to describe their objects,
and then the ray marker will find the intersection. You don't have to do it yourself anymore.
So, it's a very overfull technique, and now everyone is actually, everyone can't do this technique,
because it's very simple to program, and it gives very good results.
So, that's it, the ray matching.
Okay, cool. Yeah, and it's the thing that I find kind of intriguing by it is you can combine,
you can combine formulas, where you have something that twists space, you can combine that
in before your test of a key. It's really, really, really powerful. If you are saying you can have
a formula which models an object A, you can have another formula which models object B, and then
you can put into the game after a formula which blends the two previous formulas, and then the
object A and the object B will blend also, the shapes will blend, and you can also, as you said,
twist an object by adding some trigonometric formula to the base formula, you can stretch, you can
bend, you can do a lot of things. So, it's very, very powerful modeling tool, actually.
The problem with this is that an artist cannot use it, because obviously,
modelers and graficians, they don't know about mathematics, so it's still a coder who has to do
the modeling. We have to see 4K intros with cubes and rings and airplanes,
instead of something more beautiful, but yeah, so I think then the next step now would be to find
a way to give all this technique and put it in the hands of an artist, but I don't know how that
would happen. If anyone will come with a brilliant idea and something like that would be ideal,
that we could put this technique in the hands of the artist. Well, I imagine if you wrote,
if you wrote an editor, a modeler for this technique, it would most certainly, I would think,
have to preview, at least with ray merging, to do a polygonal sort of modeling sort of scheme.
I don't think it would work at all, and so in that sense, the rendering technique is very tied to
the model that it draws, which I find kind of intriguing, to be honest with you.
I'm looking at a picture, you have this 4K procedural graphics, called slicex, which is
fucking gorgeous, if I should say so myself. I have a couple of questions. First of all,
so once you determine where in space array has intersected with an object, how do you determine
the object's normal? Just done with techniques, which is called temporal differences.
I think that when you have your primitive and your objects defined with mathematical formula,
basically all space, or all the volume of your existing theme, becomes what we call as color
field. It's like a reality, like at any point in space, you can always measure the pressure of
air or the temperature, and that means for every point in space, you have this temperature,
and then the normal of your surfaces, they are tied or they are related to the gradient of this
field, which is a mathematical concept related also to the derivatives and other properties of this
3D color field. But basically, what we are doing is to take the intersection point and look
at it to the other point around this intersection point, and check if in this other point,
the distance to the primitive is smaller or higher than in the current point, and depending
where which of these points have closer distance and your point, you can know to which direction
the surface is oriented. It's like you are in the step from one time or in a hill, and then
you want to know how the hill is oriented, you can just look to your left, to your left and say,
okay, in my left, the hill is lower than me, and in my right, the hill is going up, so that means
my surface is oriented from right to left, and if you put the opposite like in the left,
I have more height down here, and in my right I have left, then the surface is oriented
in the other direction, so we are doing kind of this thing, but in 3D, and the technique is
called central differences, so if anyone wants to check on the internet or Google or something,
that's the term. It is very simple, you basically have to evaluate your color field or your
distance field again, four times or six times, there is a technique to do it, one is more accurate
than the other, the other one is faster, but so if you do it in the first way, you just have to
take four points, if you do it in the slower way, you have to take six points, and you evaluate
the distance field six times, and you take small formula, and you get your normal. It's very simple.
My other question is the shadows on slice x are very diffuse, I'm wondering how you're doing,
how you're determining what's in shadow. This is a big hack, it's a big trick or cheat,
but is it work quite okay? Because normally in this, in a right-tracer, in a classic right-tracer,
you have, how do you call it, have shadows, I think, like the places which are in shadow and
parts which are not in shadow are very well split into groups, like this is in shadows is not,
and you can't see the edge of the shadows, normally in a classic right-tracer, and professional
right-tracer, they have soft shadows indeed, like if you shadow, and that's what I try to do too,
but in a very different way, because professional right-tracer, what they do is to cast
thousands of shadow rays, it's like they have thousands of lights, and that gives thousands of
half shadows, but the average is a soft shadow, but I didn't want to do that, I couldn't afford
to cast thousands of rays, so I did it only with one ray, which goes from the intersection point
or the pixel you are lighting to the light source, and in this ray, I was taking five points along the
ray that were echidistant, like all at the same distance from each other, and in this five points,
I was computing again the distance, the distance to the closest primitive, I was just evaluating again
the distance field, and if the five points are very close to something, then your point is most
likely to be in shadow, in complete shadow, but if only two of them are very close to an object
and the other three are far, then your shadow is probably going to be softer, like we have a bit more
light, and by using these five points and the five distances to any geometry, I was kind of mixing
all these values together to give a soft shadow. It really doesn't look bad for five points.
No, it works quite okay, but it's very tuned for this, I mean, all the parameters of this
technique were tuned for this image, but I generally think that works for everything, but
well, it was good enough, and it is work, and yeah, yeah, I don't know, I'm quite proud of it,
because it looks pretty good.
Do you know, as I've heard from you before, and unfortunately, you did a panel for an
vision, and the recording I had of it was cut halfway off, and so you're beginning,
if you don't mind me asking, you're beginning to, you're going to describe, it seems that there
is a different computational difference between primary rays and secondary rays. It's much less
expensive for secondary rays, as opposed to how expensive it is for traditional ray tracers,
is do I understand that correctly?
Yeah, but yeah, and also the thing was that in a traditional ray tracer to do these effects
beyond the pure reflective and half shadows, like, so normally in a ray tracer to do the
soft shadows, or ambient occlusion, or global illumination effects, which really bring a lot
of richness to the image, these effects are very expensive because you have to cut some of
ray, but with a distance field, you can apply tricks as the one I just described of the soft shadows,
and you can't get the same effects in a very cheap way, so while a normal ray tracer
spends most of the time in the secondary rays or in the special effects, with a ray matching
in distance fields, it's actually this special effect takes very, very little time,
a lot less than the basic rendering, which is completely the opposite of a normal renderer,
and that makes the technique very interesting. For example, in this image with the soft shadows,
and on that you also have ambient occlusion, which is a technique that brings extra shadows to
the parts of the model, which are very close to some geometry, like when you have a wall,
and the floor, and then this part of the scene where the floor and the wall are connecting to
that part, normally should be a bit darker, a bit more dark than the center of the wall,
where it's really exposed to the light, while the bottom part is more in shadow. So this kind of
effects and ambient occlusion effects are normally very, very expensive, but with the distance
fields, you can do them almost for free, like it takes less, less than, I don't know, 5% of the
rendering time. Well, okay, how are you doing the pillars that reach the floor? How are you doing
the shadows that go around that? So the ambient occlusion is done again by using
tweaks of the distance. So you have a point, and basically what you want to do is to know if this
point that you are lighting or shading, you want to know if this point is very, how to say
exposed to the light sources, or if it's really hidden behind some geometry, and if the light
is not really able to access that point. So the geometry of the pillar, the geometry of the
ground, or the ground, or the monster, or the whatever. So basically you take a few points,
again, around your shading point, and you see if these points are inside the geometry or not,
if they are really floating in there, and that you can do by taking the distance field and
evaluating it in this point. So again, let's say you take 5 points around your point, your
shading point, and you say, okay, at this point inside some geometry, like a column, or they are
below the floor, and if three of them, they are, and two of them are not, it means that this point
is not very, well, it has hidden behind the geometry. So all of them were just floating in there,
and not inside of anything, then this point is actually very exposed to the light, and then it's
very light. So the point isn't, you're not computing 5 rays from one single point, you're
computing it from a volume. That makes a little bit more sense. Normally in a ray tracer,
you would be done with cutting thousands of rays, and here you just have to, you don't even have
to cut any ray, evaluate the function a few times here, and there are a few points, and voila,
you have the shading, and that's really cool. There are any heuristic methods, is there anything
that can be gained from primary rays, the secondary rays, would find useful, do you think?
I mean within the GPU sort of frame architecture, it seems like that wouldn't be possible, but
are there any tricks that you've used, for us speeding things up based on either pre-computed
data or... No no, no no no no, no no no, no pre-computation at all. Everything done
on the fly. Good Garage. So yeah, there is no refundations or anything. Actually, it's very plain
quote, there there is no special optimizations or anything. On your GPU you're so fast today,
that especially when you are calling 4K production, you don't really care about the speed anymore,
it's just about how much you can fit in the 4K.
And to make more room into your executable, you just drop all the acceleration techniques for all the tricks.
So normally we just call the plane basic alcoholism without any speed up for any trick
and just let the hardware handle it.
And in this case, also the recent and other tricks,
other than the fast and interclusion and the soft shadows,
which are not really a trick, but a technique you could say.
It's interesting.
Now, are you testing whether an object is within or without a particular geometry,
are you testing every geometry per race step?
Yes, just right now, yeah.
Normally one should use an uptree or something to discard objects that are too far, for example,
but in the case of all the 4K productions, they have long so far, everything was tested for every race.
But really it's really brute force, a really brute force approach.
But it works quite okay.
However, now every people doing 4K productions with rain marching,
we are discussing new ways to accelerate all these, to make it even faster.
And right now, this is in Poet, a very nice red, the one you've started, by the way.
Well, most of the coders who have been using this technique
are discussing how we could make it faster.
So, I propose to use 3D texture, I need to pre-compute some of the distance field
and store it in a lookup table or in a 3D texture.
Others were speaking about casting many rays in one go,
like a complete group of rays, and try to make them move together,
so that you can save computations, like you can do the computations only once,
for all these rays.
And in case the computations are valid for them,
just keep on doing like that until you have to break the group of rays into individual rays.
So, there is many ways we can probably speed it up.
But the problem is all these techniques will take more space,
or they will take half kilovide, a quarter kilovide, or one kilovide of the code.
So, I don't know what will happen, but if it was not,
if we were doing this in 4 kilovide and we were doing it in demos or 64K,
then yeah, I think there would be a lot of tricks we could apply for accelerating on this.
But in 4K, I'm not sure yet if we will see any of these techniques really being applied.
I don't know.
Well, the simple geometry is here without fancy optimization techniques.
Still look pretty cool.
I think they still have a little bit of time to lose, if that makes sense.
Yeah, I think we still will see spheres and cubes on this thing for one year or so.
They look nice.
Most of these 4K intros have been in the last year or two years.
They are very, very nice.
You can't enjoy them a lot, even if they are still sphere.
They are shiny.
They have shading effects.
They have the right color, the right music.
They look very, very nice.
But yeah, I hope we will see one day.
I think one day in two years or so, we will start to see more complex geometry and so on.
For example, these graphics we were discussing with the pillars and the columns and the monsters and all that.
Apparently, they were really working.
But it runs at 10 frames per second already, today, rent GPUs.
So this was released one year ago, I think, or two years ago.
At that time, I think it was like half frame per second or 0.5 frames per second.
And today it's already 10 frames per second.
So I wouldn't use a price if in two years more, three years, we would see these things real-time, completely real-time.
With the monster moving around and destroying the columns and the roof falling down on these kind of things.
So yeah, probably, I don't know.
But we have to dream, huh?
Well, it's still the fact that we can do ray tracing alone real-time is still kind of amazing to me.
Does that make sense?
Well, actually, normally, in the demo scene, when we think about ray tracing, we think about planes and cylinders.
But there is another scene out there, which are, they have been ray tracing on polygon, not in spheres and planes, but really in normal meshes and 3D objects.
Like, don't in Max or Maya or whatever.
They're getting a good performance from this?
Oh, yeah, yeah, yeah.
And also in that scene, three years ago, and even worked professionally on that.
And you can render a few million polycons in real-time with a dual core machine today.
So, yeah, it's quite amazing.
Actually, in the demo scene, we are quite slow.
We didn't cut up with them because they are releasing nice ray tracing.
They're all based on KD-3s, and opt-3s, and bonding volume hierarchies, and other techniques to accelerate the deflection.
And they are using very specific, special ways of storing data in the memory, which is very efficient for cache, coherence, and so on.
And basically, you can do real-time ray tracing of a few million polygons.
You need a lot of memory to store all the KD-3 and opt-3s in memory, but it's absolutely doable today.
So, yeah, it's very accurate.
They're getting good reflections and other...
Normally, they have primary ray and shallow ray.
Then, I invented some techniques to do ambient occlusion in real-time by casting just four ray per pixel of ambient occlusion,
blurring ambient occlusion information in screen space.
But, yeah, but normally, it's simple effects, no reflections, and so on.
But anyway, I think the reflections are...
They are not that important in the end, I think, in reality.
In the demo scene, we have a view scene of them.
We like to have spheres reflecting spheres, which reflect more spheres, and so on.
But when you look around you in reality, I don't know how many objects you see which are reflective.
You know, I have here my window, which is now reflecting a bit.
I don't see many reflective objects.
I don't know, in the demo scene, we have this footage of reflecting spheres.
I don't know why.
Well, it's very impressive to see a sphere reflecting a sphere.
Yeah, it's cool.
For some reason, it's like hypnotizing.
I don't know why, it's very cool.
But if you look around you, you don't see that many reflecting spheres.
I walk here in my apartment, I go to the street to walk and I don't see reflective spheres anywhere.
They look very cool, yeah.
I'm looking around right now, and aside from the CDs that are here, of course,
they don't really use it to anything.
The only thing that there isn't anything that's reflecting anything aside from light.
But that's not really reflecting, right?
What's that?
Well, everything reflects a bit of light, of course, because that's the principle of the principle of global illumination,
like the light hits an object and that light is kind of bounded or reflected in another direction and so on and so on.
But the perfect reflection, like a major reflection, we don't see that many, I think, during the day.
So, you know, if I have you on the phone, I'm sorry, you probably get this.
Yeah, I have to talk about elevated.
Okay, let's go to elevated, we'll be back in one second.
Okay.
Okay.
Okay.
Okay.
Okay.
All right, we're back.
That was elevated.
The P out ID on this is 52938.
Now, this is a 4K demo, and what party was this released at?
Breakpoint.
Breakpoint 2009.
Yeah.
It seems pretty popular as far as that was.
Yeah, yeah.
I don't know what we did, but it became very popular and really quickly, in fact.
It's like, I remember, so it was a collaboration, collaboration between RGBA and TVC.
Yeah.
And the guys of TVC, they made atrium before one breakpoint 2008.
How did curiosity, who did the synth?
Because the synth is gorgeous, in my opinion.
Oh, amazing.
When they sent me the first version of the music, I was like, I was like, wow, we are going to win.
I don't know what images we will have, but we are going to win anyway.
It was really good.
So, these guys, they made this very other successful 4K intro.
And apparently, they were very happy because in YouTube, they got like 40,000 views or something in one week.
And the guys were going crazy because we got 40,000 in two days, not in a few weeks, but in two days.
So, I don't know what happened with the release, but people really liked it a lot.
And I think in YouTube, we are now in the 400,000 views or something, which is a lot.
Especially, taking into account that we don't have books or dancing girls or porn at all.
Just mountains and a 4K intro, and lots of people is watching it.
So, we are really, really happy.
Well, it looks like a, it's very photo.
It looks very photo-esque.
You have a sort of, it looks like you have everything is not lit the same.
It's kind of darker on the edges, maybe.
Yeah.
You have sort of a lens, sort of specular sort of.
Yeah, actually, this was a bit my, the thing I wanted to try this time with this production,
to do something that didn't look too much computer-made.
It looks computer-made, of course, but I tried to apply all these effects you have in real camera.
Like, indeed, darkening the borders of the screen.
You have the grain or the noise in the image.
You have the color distortion.
You have light flickering, like the screen is all the time flickering.
The intensity, the overall intensity of the image.
Oh, is it?
I could have watched again.
Yeah, yeah.
Well, you have to watch the real time version, because in the video, these effects are just,
most of them are gone with the NPEG or the VIX compression.
You'll have to, I'll have to go to my friends.
It's funny.
Yes.
I just have a horrible computer as far as demos are concerned.
I have time to change.
Okay.
Yeah, that's, I will have to change.
I know, because my computer is quite crappy, too.
And in fact, I did program elevated.
At a very, very, very low resolution, like 180 pixels, so just 100 pixels.
And then I could see the real time.
Because normally it was running at 2FPS, 3FPS, 20 seconds.
So actually, most of the productions I do, I do them.
I make them in very, very small window.
And then I see them in big screen only in the party.
I thought before.
Really?
Are you pretty confident they still work correctly?
Or do you think anything will be broken?
Have you had that experience?
That curiosity where you produce something?
They will become incompatible or something.
I don't know.
Well, will the frame rate just be as low because of something you had not seen with this resolution or something like that?
Have you had any surprises?
No.
Well, the surprises are that it looks nicer in big screen.
Otherwise, no, no, no, no.
I can code in small resolution with no problem.
From time to time, I rendered a video to see what I'm doing.
But normally, it works quite okay for me to do this in small resolution.
No, out of curiosity, how much in elevated are you doing in the CPU?
How many I'm doing on the CPU for elevated?
Just what are you doing?
I mean, the terrain looks like it's probably vertex shader.
Yeah, well, we are in the CPU.
We are just playing the music, of course, which is computed on the CPU.
And then, at runtime, we are just doing the parameter interpolation.
Like, there is some parameters to control the screen intensity or the camera position.
And these things are interpolated on the CPU and tend to the GPU.
But basically, the CPU is idle.
It's really idle.
All the magic is happening on the GPU.
Even the camera movements, because the parameters are computed on the CPU,
but the real movements are done in the GPU.
I think it's the first, one of the first intros doing this.
Then, classic approach to move the camera on the CPU,
and just send the camera position to the GPU, to the shader.
But in this case, we are sending the parameters to the shader,
who is computing really the camera position.
Well, the shader has the benefit of knowing the geometry.
Yes, exactly.
Because indeed, the geometry is the real terrain shape that's defined on the GPU,
too, with a vertex shader.
The CPU doesn't know anything at all about the mountain.
It doesn't even know what it's rendering.
The CPU just sends a regular grid, flat plane of triangle,
and it's the GPU who converts that into a terrain.
So it's the GPU who knows how to make the collision detection,
or avoid a peak or something.
That's why the camera is on the GPU.
Okay, cool.
If you don't mind me asking, do you have any particular demo
that you want us to be next, whether you're of your own creation,
or perhaps someone else that you think is pretty cool?
Oh, demo that I like.
Yeah.
Preferably your own, right?
Because we're talking to you, so...
Okay, from... I like elevating.
I like elevating a lot.
Yeah, I'm really in love with nature,
and especially with the rain, and snowy landscape.
Well, yeah, you did a...
There's another procedural graphic that you did.
I don't recall the name of it.
It's a forest landscape.
And that's also shown from one time.
And actually, I've been doing terrain rendering.
I think one of my very first effects before I knew the demo scene
was already terrain, fact-alterrain.
And since then, since 97 or 96,
I have been doing terrain for almost every year,
in a way or in another.
In a 4K, in a 64K, in a procedural graphics,
in my own projects, always.
And I really love them.
I guess it's not because in Spain,
I was born in the north of Spain, which is very cold,
and snowy, and I spent all the winter
when I was a child in the mountains,
skiing, and so on.
And I like it.
I love snow and mountains.
So, I really like elevating.
And, yeah, I don't know.
I guess if I do anything else again,
any 4K or 64K, it will be with nature again,
like mountains and these things.
So, in that sense, I like elevating.
And I'm very proud of it, also.
And it was a great experience to do it
with the kind of TPC.
How did Nico at the party
did everyone cheer when I wanted to play
and did everyone really, really like it?
I mean, I'm judging this from the...
It was first place, right?
And I was not at this party, so I don't know.
So, I don't know, because normally,
when I make a production,
and it goes into the competition,
during the competition, I'm very nervous.
I mean, the most...
I'm competing since the 98,
doing many productions a year.
Normally, it was in Spain,
but then also in other countries.
But still, after...
I think they have no 4K production.
So, for me, still today, I get very nervous
when they have projected on the big screen.
So, when we were elevated,
I was very nervous.
I don't remember much.
In fact, I remember people clapping,
and I was enjoying a lot.
So, I went with Mentor,
the other color.
We went to the very first row.
At the back point,
we went to the first places
to sit in front of the screen,
to sit in this huge screen they have.
And I was enjoying it,
and I remember being very nervous,
but I think people liked it a lot.
And they were clapping,
and then came and said,
oh, this is the fucking...
whatever.
But everything came later,
but during the projection,
I was just like...
Well, anyway, in breakpoint,
and I think it's the same in assembly,
they project what they think
are the most in the end of the competition.
So, keep the best production to the end.
So, the fact that the elevated was projected,
the last one was already like a good sign, of course.
That screen was so nervous.
Yeah, you're doing it.
It's nice to like seeing your child
being alone for the first time.
Yeah, the fact that you develop it
in a kind of a restricted,
sort of manner,
to see it on the big screen.
It's such a high resolution.
I'm sure it's very exciting.
It's exciting, yes, yes.
And surrounded with a lot of people,
and with your friends,
it was a bit special, yes.
It's really nice.
So, that's why I think that
every demo singer should go
to demo parties, because...
Especially if you have to do...
If you have a demo,
or an intro, you have to go to a party.
Because, for example,
I made another 4K intro
two years ago, I think,
it was called Stiletto.
It was a walking woman.
It went to the competition of assembly.
So, I went...
It is competing,
apparently.
But I was not there.
I couldn't go.
And then it got...
I think it got second position,
but it has very good reviews.
And the fact that I made a position
and not being able to watch it live,
it was really catastrophic for me.
Because then I watched some live records,
like someone went with a camera
and recorded how people reacted to the demo
in the big screen,
and they liked it a lot,
and they clapped,
and so on.
And I wasn't there to watch it,
so it was too bad, too bad, too bad.
So, I think anyone should go to a party.
And if you have a demo,
go to a party,
and watch it on the big screen
with your friends and your people
that you don't know yet,
but they will become your friends later,
and they will clapped,
and it's really, really an experience.
It's great.
Wow.
It's really nice.
So, once the next party,
you're going to...
I'm going to function in Hungary.
Because that's in September 25,
I think, Budapest.
So, it's the guys of Conspiracy
and the Hungary and the Moshing
which are organizing it.
It's a very small party,
but it's very, very nice.
I like it a lot.
I have gone the last two years,
this will be the third time,
and it's very, very nice.
It's completely different than breakpoints,
in the sense that it's very familiar,
this is very small,
it's quiet,
but we really enjoy a lot.
Normally, you have good production also.
So, this summer,
I didn't go to any party.
It's a breakpoint...
Yeah, it's a breakpoint.
I didn't go to any party.
I'm really waiting for it,
so that's function.
Right, cool.
I hope you have a lot of fun,
and I don't say hi to Gargai for me.
That's the only person I really know
from the Hungary scene,
at least.
So...
He's the organizer,
one of the organizers.
Oh, yeah.
How many of the problems have been organizers,
is that he will be very busy
on the time I'm stressed,
because he has to organize the compo,
but you know the story.
So, they are there for the party,
but they are not really enjoying.
So, Gargai will be there,
but he will not enjoy that much.
Do you mind me asking without,
I don't know how secretive you are
with RGDA,
but do you have any,
pretty cool frameworks that you've developed over the years?
Do you have a very nice tool
that you are using?
Like, what tools have you developed
within this group?
How are you going to be surprised,
because we don't have any tools?
Really?
Yeah.
That's okay.
Yeah, well,
it's the way we work,
or at least the way I work,
and because I'm the only active one,
the only active member of RGDA
and the one who decides, let's say.
So, no tools at all.
I don't like writing tools.
I just like writing demos.
I really dislike writing,
making user interfaces,
and plugging for 3D smarts
and keeping compatibility,
and it's an endless story, I think.
I don't have much time to do problems,
and I don't spend much,
in fact, at the time,
and the time I invest on demos,
it's really for making demos,
not the tools.
So, we don't have any tools.
We just use Visual Studio,
so the C compiler of Microsoft
and tap it.
Pretty cool.
Yeah.
So, that means that all the animations
are done with formula,
and we don't have spline editor,
or the tier-curse editor,
or anything.
So, we do everything just with formula,
and we have to move an object,
we have to put object dot,
position dot x equals
sign rules of time
through exponentials,
and that's the way we do animation.
And so on and so on.
And I like it,
because I don't know,
it takes lots of time to do things,
like to get the right movements,
the right animations you want,
or the right textures,
the right, whatever you want.
But I don't know,
it's a different way of thinking,
because the other way of doing it
is what you would do if you were doing a game,
or if you were a game developer,
and if I wanted to do that,
I would get a game developer job.
I don't know,
I prefer to do it in another way.
I like it.
So, we don't have any tools.
We use Visual Studio photo shots,
of course,
to check from time to time things,
and that's it, I think.
Yeah.
So, it's a bit disappointing,
because normally most groups
have huge tools,
we do everything from textures,
to animations,
to 3D objects,
to rendering,
they have exporters,
they have plugins,
they have millions of things,
but we don't have anything.
Yeah.
I like it.
It's serious.
That was our impressive,
nonetheless.
I mean, I'm not saying that
there would be more impressive,
but the fact that you're doing these
from scratch every time,
is pretty cool.
Yeah. And I find it pretty exciting.
Like, for example,
with Elevated,
so Elevated, yeah,
the rain and so on.
Many people are telling me,
okay, which images did you use as reference,
or which videos did you download
to,
to, yeah, as reference,
or to try to mean it,
and so on.
I didn't use anything.
I didn't even go to Google
for watching images or anything.
I like the idea of building everything,
just from my mind,
through formula.
I mean, I find that very exciting.
So, if there was analysis
designing the mountains,
and designing the texture,
then it wouldn't be that funny for me anymore.
I still like to watch demos, of course.
The classic demos, I mean,
where they are done with Photoshop textures,
and 3D Snacks measures.
That I enjoy watching.
As a creator,
active demo thinner,
or programmer,
I like to follow this other process
of just thinking on something in my mind,
and then finding the formulas
that will bring it to the screen,
and building something out of nothing.
That's really I like.
I think it's very exciting.
Okay.
Yeah.
I think I'm going to,
I think I'm going to close this interview
to be honest with you, so.
Okay.
Thanks for, thanks for,
thanks for,
thanks for having the time.
Thank you.
Yeah.
Okay.
And take care,
and I guess we'll be closing
with, there's this, this,
what, let's see,
what should we close with?
Hmm, maybe,
the instant sound music,
of the SPS,
CD4,
demo,
I love it.
Okay.
All right.
We'll see you next week.
Or whenever.
It's, it's kind of haphazard,
but I like seeing,
see you next week.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
Yeah.
You're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows
how to do it
You're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one
You're the only one who knows how to do it, you're the only one who knows how to do it
You're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one who knows how to do it, you're the only one
